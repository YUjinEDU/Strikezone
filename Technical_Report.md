# 기술 보고서: AR Strike Zone 개발

**과목**: 오픈소스프로그래밍
**제출일**: 2025.12.19

---

## 1. 프로젝트 개요

본 프로젝트는 단일 웹캠만을 사용하여 야구공의 투구 궤적을 추적하고, 이를 증강현실(AR)로 시각화하여 스트라이크/볼을 자동으로 판정하는 시스템입니다. 고가의 장비 없이 파이썬과 오픈소스 라이브러리(OpenCV)만으로 투구 분석 시스템을 구현하는 것을 목표로 하였습니다.

## 2. 핵심 기술 상세

### 2.1 ArUco 마커를 이용한 3D 좌표계 설정

단안 카메라(Monocular Camera)는 기본적으로 깊이(Depth) 정보를 알 수 없습니다. 이를 해결하기 위해 **ArUco 마커**를 기준점으로 사용했습니다.

- `cv2.aruco.estimatePoseSingleMarkers` 함수를 사용하여 마커의 3D 자세(Rotation Vector, Translation Vector)를 구합니다.
- 이 마커를 원점(0,0,0)으로 하는 월드 좌표계를 정의하고, 공의 위치를 이 좌표계 기준으로 변환하여 투구 궤적을 계산했습니다.

### 2.2 핀홀 카메라 모델을 이용한 거리(Depth) 추정

공의 3차원 위치 중 가장 중요한 깊이(Z값)는 **핀홀 카메라 모델**의 원리를 역이용하여 추정했습니다.

- **원리**: 물체가 카메라에서 멀어질수록 이미지 센서에 맺히는 크기는 작아집니다.
- **수식**: $Z = \frac{f \times R_{real}}{R_{image}}$
  - ($f$: 초점 거리, $R_{real}$: 공의 실제 반지름, $R_{image}$: 이미지 상의 반지름)
- 이를 통해 공의 크기 변화만으로 대략적인 거리를 계산할 수 있었습니다.

### 2.3 칼만 필터(Kalman Filter)를 통한 궤적 보정

영상 처리로 얻은 좌표는 조명이나 노이즈로 인해 떨림이 심했습니다. 이를 보정하기 위해 **칼만 필터**를 적용했습니다.

- 이전 프레임의 위치와 속도를 기반으로 다음 위치를 **예측(Predict)**하고, 실제 측정된 위치로 **업데이트(Update)**하여 부드러운 궤적을 얻었습니다.
- 결과적으로 공이 빠르게 움직이거나 잠시 놓쳤을 때도 끊기지 않는 궤적을 그릴 수 있었습니다.

## 3. 개발 과정 및 시행착오 (Trial and Error)

Git 커밋 기록(`git log`)을 되돌아보며 겪었던 주요 시행착오들은 다음과 같습니다.

### 3.1 초기 좌표계 및 시각화 구현 (3월 ~ 4월)

- 초기에는 단순히 공을 인식하는 것에 그쳤으나, `0fa236f` (4월 9일) 커밋에서 **전광판(Scoreboard)**을 적용하며 AR 요소를 본격적으로 도입했습니다.
- 하지만 2D 이미지 위에 텍스트를 띄우는 것과 3D 공간에 물체를 그리는 것의 차이를 이해하는 데 시간이 걸렸습니다.

### 3.2 3D 궤적 구현의 난관 (5월)

- `40860c2` (5월 30일) 커밋에서 **"3D 궤적 추가"**가 이루어졌습니다.
- 그 전까지는 2D 평면에서의 움직임만 추적했으나, 투구 분석을 위해서는 깊이 정보가 필수적이었습니다. 공의 크기 변화를 거리로 환산하는 과정에서 오차가 심해 캘리브레이션을 여러 번 수행해야 했습니다.

### 3.3 판정 로직과 성능 최적화 (10월 ~ 12월)

- `77501e8` (10월 29일) 커밋 메시지인 **"main 7 완료 하지만 스트라이크 판정 미완성"**에서 볼 수 있듯이, 정확한 스트라이크 존 통과 여부를 판단하는 것이 가장 어려웠습니다.
- 단순히 공이 네모 칸 안에 들어왔느냐가 아니라, **"입체적인 스트라이크 존을 통과했느냐"**를 판단해야 했기 때문입니다. 이를 해결하기 위해 스트라이크 존을 두 개의 가상 평면(앞면, 뒷면)으로 정의하고 벡터 연산을 도입했습니다.
- 최근 `f9605b2` (12월 3일) 커밋에서는 궤적 그리기 기능을 잠시 주석 처리하고 **"검출기를 업그레이드"**하는 시도를 했습니다. 실시간 처리 속도를 확보하기 위해 불필요한 연산을 줄이고 HSV 색상 범위를 최적화하는 과정을 거쳤습니다.

## 4. 결론 및 향후 계획

이번 프로젝트를 통해 컴퓨터 비전의 기초인 좌표계 변환부터 필터링 알고리즘까지 실제 코드에 적용해 볼 수 있었습니다. 현재는 색상 기반 검출에 의존하여 조명 변화에 취약하다는 단점이 있습니다. 향후에는 딥러닝 기반 객체 인식(YOLO 등)을 도입하여 더욱 강인한 추적 시스템으로 발전시킬 계획입니다.
