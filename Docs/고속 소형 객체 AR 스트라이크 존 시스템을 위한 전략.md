# Strategy for a High-Speed Small Object AR Strike Zone System고속 소형 객체 AR 스트라이크 존 시스템을 위한 전략

## Introduction & Challenges소개 및 과제

Designing an **AR strike zone system** that tracks a **fast-moving, small object** (e.g. a baseball) in real time poses unique challenges. Such objects occupy only a few pixels (often <32×32) and move rapidly, causing **motion blur and large frame-to-frame displacements**[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=general%20object%20detection%20and%20tracking%2C,2)[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=Despite%20recent%20advances%20in%20the,5%5D.%20Balls). Background clutter and changing lighting further complicate detection[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=Despite%20recent%20advances%20in%20the,5%5D.%20Balls). **Standard object detectors (e.g. YOLO/Tiny models)** struggle with these conditions – their accuracy on small objects remains relatively low[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=Despite%20recent%20advances%20in%20the,5%5D.%20Balls). Additionally, naïve tracking-by-detection can fail when the object’s trajectory changes abruptly or when detections are momentarily lost. To overcome these issues and ensure an **academically novel contribution**, we propose an integrated strategy with four pillars: **(1)** a new lightweight model architecture specialized for fast small objects, **(2)** physics-informed data augmentation for extreme speeds, **(3)** embedding physical trajectory reasoning into the model or pipeline, and **(4)** a hybrid detection–tracking algorithm that surpasses YOLO/Tiny limitations. Below, we detail each component and outline an implementation roadmap.빠르게 움직이는 작은 물체(예: 야구공)를 실시간으로 추적하는 AR 스트라이크 존 시스템을 설계하는 것은 고유한 과제를 제시한다. 이러한 물체는 몇 픽셀(<32×32인 경우가 많음)에 불과하고 빠르게 움직여 모션 블러와 프레임 간 큰 변위를 유발하며 arxiv.orgpmc.ncbi.nlm.nih.gov. 배경 잡음과 변화하는 조명은 탐지를 더욱 복잡하게 만든다 pmc.ncbi.nlm.nih.gov. 표준 객체 탐지기(예: YOLO/Tiny 모델)는 이러한 조건에서 어려움을 겪으며 — 작은 물체에 대한 정확도는 상대적으로 낮게 유지된다 pmc.ncbi.nlm.nih.gov. 또한, 단순한 탐지 기반 추적(트래킹-바이-디텍션)은 물체의 궤적이 급격히 변경되거나 탐지가 일시적으로 소실될 때 실패할 수 있다. 이러한 문제를 극복하고 학문적으로 새로운 기여를 보장하기 위해, 우리는 네 가지 축으로 구성된 통합 전략을 제안한다: (1) 빠른 작은 물체에 특화된 새로운 경량 모델 아키텍처, (2) 극한 속도를 위한 물리 기반 데이터 증강, (3) 물리적 궤적 추론을 모델 또는 파이프라인에 내장, 그리고 (4) YOLO/Tiny의 한계를 능가하는 하이브리드 탐지–추적 알고리즘. 아래에서 각 구성 요소를 상세히 설명하고 구현 로드맵을 제시한다.

## 1. Lightweight Architecture for Fast Small Object Detection1. 빠른 소형 객체 탐지를 위한 경량 아키텍처

Achieving high accuracy on small, fast objects **without heavy computation** calls for innovations in model design. One key is **multi-scale feature fusion** that preserves fine details from high-resolution layers. Modern detectors use Feature Pyramid Networks (FPN) to combine deep and shallow features; however, directly upsampling deep features can cause a semantic gap and dilute small-object features[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=In%20terms%20of%20semantic%20fusion%2C,focused%20on%20improving%20the%20traditional)[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=these%20methods%20have%20improved%20the,scale%20features). Recent research addresses this by **restructuring the backbone and FPN** specifically for small objects. For example, **SEMA-YOLO** (2025) enhances YOLO by adding an extra **shallow detection head** on a higher-resolution feature map (P4 instead of P5) and reducing backbone depth, which increases the pixel coverage for small targets[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=fusion%20mechanism%2C%20the%20proposed%20framework,C3k2%20structure%2C%20is%20introduced%20to)[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=Shallow%20Layer%20Enhancement%20,in%20dense%20and%20complex%20scenes). It also introduces a **Receptive Field Attention (RFA)** module to adapt the convolutional receptive field, improving fine-grained feature extraction for tiny objects[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=Receptive%20Field%20Attention%20Convolution%20Module,and%20sensitivity%20to%20small%20objects). In a similar vein, Wu _et al._ (2025) propose focusing detection **primarily on high-resolution feature layers** while using low-resolution layers only to provide context[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=avoiding%20the%20high%20computational%20cost,The%20details%20are%20as%20follows)[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=structure%20so%20that%20small%20object,The%20details%20are%20as%20follows). They replace heavy deep-layer residual blocks with a light **Spatial Pyramid Pooling** module to widen context without high cost, and decouple semantic fusion from shallow feature extraction[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=blocks%20in%20the%20deep%20layers,The%20details%20are%20as%20follows)[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=To%20address%20this%2C%20we%20design,from%20the%20extraction%20of%20shallow). This **decoupled, multi-scale design** preserves small-object detail and yields a **lightweight detector** that retains accuracy[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=Feature%20Extraction,semantic%20integration%2C%20thus%20partially%20reducing)[nature.com](https://www.nature.com/articles/s41598-025-16878-6?error=cookies_not_supported&code=1e05ae14-8ed4-4ad3-9716-1344fd996638#:~:text=slower%20inference,computational%20cost%20and%20parameter%20size).무거운 계산 없이 작고 빠른 물체에서 높은 정확도를 달성하려면 모델 설계의 혁신이 필요하다. 핵심 중 하나는 고해상도 층의 미세한 세부를 보존하는 다중 스케일 특징 융합이다. 최신 검출기들은 깊은 특징과 얕은 특징을 결합하기 위해 Feature Pyramid Networks(FPN)를 사용하지만, 깊은 특징을 직접 업샘플링하면 의미적 격차가 발생하고 작은 물체 특징이 희석될 수 있다 nature.comnature.com. 최근 연구들은 소형 물체를 위해 백본과 FPN을 재구성하는 방식으로 이 문제를 해결하고 있다.예를 들어, SEMA-YOLO(2025)는 더 높은 해상도 특징 맵(P5 대신 P4)에 얕은 탐지 헤드를 추가하고 백본 깊이를 줄여 소형 표적에 대한 픽셀 커버리지를 증가시키는 방식으로 YOLO를 향상시킨다 mdpi.commdpi.com. 또한 합성곱 수용 영역을 적응시키는 Receptive Field Attention(RFA) 모듈을 도입하여 아주 작은 물체의 미세 특징 추출을 개선한다 mdpi.com. 유사한 맥락에서 Wu 등(2025)은 저해상도 층은 컨텍스트 제공에만 사용하고 주로 고해상도 특징 층에 검출을 집중할 것을 제안한다 nature.comnature.com.그들은 비용이 많이 드는 심층 레이어의 잔차 블록을 가벼운 Spatial Pyramid Pooling 모듈로 대체하여 높은 비용 없이 컨텍스트를 확장하고, 의미적 융합을 얕은 특징 추출과 분리한다 nature.comnature.com. 이러한 분리된 다중 스케일 설계는 소형 물체의 세부를 보존하고 정확도를 유지하는 경량 검출기를 만든다 nature.comnature.com.

 

Another technique is to expand the effective receptive field _without_ downsizing features. **Dilated convolutions** can be inserted to capture broader context around small objects[mdpi.com](https://www.mdpi.com/2076-3417/15/22/11882#:~:text=model%20architecture%2C%20e,more%20contextual%20information%20around%20suspected). For instance, the **MDSF-YOLO** architecture uses a _multiscale dilated sequence fusion_ network to efficiently gather contextual cues around tiny objects, boosting detection in cluttered scenes[mdpi.com](https://www.mdpi.com/2076-3417/15/22/11882#:~:text=model%20architecture%2C%20e,more%20contextual%20information%20around%20suspected). **Deformable convolutions** are likewise beneficial – by learning spatial offsets, they can “bend” the receptive field to better align with small or motion-blurred objects. This helps the network latch onto the object’s shape despite rapid movement. **Attention mechanisms** can further enhance feature quality: e.g. a lightweight **Receptive Field Attention** block (as in SEMA-YOLO) or channel/spatial attention modules (CBAM, SE, etc.) highlight faint object features amidst background noise[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=Receptive%20Field%20Attention%20Convolution%20Module,and%20sensitivity%20to%20small%20objects). In practice, a **combination of these modules** is ideal. We propose a **Tiny-StrikeNet** architecture with: (a) a shallow-enhanced backbone (e.g. using an extra detection head at a higher scale like _P4_ feature map[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=fusion%20mechanism%2C%20the%20proposed%20framework,C3k2%20structure%2C%20is%20introduced%20to)), (b) an improved feature fusion (e.g. an adaptively weighted fusion akin to ASFF to merge multi-scale features without overwhelming shallow layers[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=classification%2C%20especially%20in%20dense%20and,complex%20scenes)), and (c) context modules like dilated or deformable conv layers in early stages to capture the ball’s surroundings[mdpi.com](https://www.mdpi.com/2076-3417/15/22/11882#:~:text=model%20architecture%2C%20e,more%20contextual%20information%20around%20suspected). By **fundamentally reducing information loss** during downsampling[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=feature%20loss%20during%20downsampling%20and,enhanced%20Adaptively%20Spatial%20Feature%20Fusion) and tailoring the network for small-object features, this model aims to outperform generic YOLO/Tiny models in both precision and speed. Importantly, many of these changes (shallow heads, fused features) add minimal overhead – for instance, SEMA-YOLO’s multiscale adaptation module achieved better tiny-object detection _without significant computational cost_[mdpi.com](https://www.mdpi.com/2076-3417/15/22/11882#:~:text=The%20SEMA,object%20detection%20%5B23%5D.%20Others%20have). Overall, this architecture is **lightweight-by-design**, leveraging modern tricks (e.g. **Ghost modules**, depthwise separable conv) to further cut complexity if needed, ensuring the model can run in real time (~30–60 FPS) on modest hardware.

또 다른 기법은 특징을 축소하지 않고 유효 수용 영역을 확장하는 것이다. 팽창 합성곱(dilated convolution)은 작은 물체 주변의 넓은 문맥을 포착하도록 삽입될 수 있다mdpi.com. 예를 들어 MDSF-YOLO 아키텍처는 다중스케일 팽창 시퀀스 융합 네트워크를 사용해 작은 물체 주변의 문맥 단서를 효율적으로 수집하여 복잡한 장면에서의 검출을 향상시킨다mdpi.com. 변형 합성곱(deformable convolution)도 유익한데 — 공간적 오프셋을 학습함으로써 수용 영역을 물체에 더 잘 맞추어 ‘휘게’ 할 수 있다. 이는 빠른 움직임에도 불구하고 네트워크가 물체의 형태를 포착하도록 돕는다. 어텐션 메커니즘은 특징 품질을 더욱 향상시킬 수 있다: 예를 들어 경량 수용영역 어텐션 블록(SEMA-YOLO에 사용된 것)이나 채널/공간 어텐션 모듈(CBAM, SE 등)은 배경 소음 속에서 희미한 물체 특징을 강조한다mdpi.com. 실제로는 이러한 모듈들을 조합하는 것이 이상적이다. 우리는 다음을 갖춘 Tiny-StrikeNet 아키텍처를 제안한다: (a) 얕지만 향상된 백본(예: P4 피처 맵과 같은 더 높은 스케일에 추가 검출 헤드를 사용하는 경우)mdpi.com, (b) 개선된 피처 융합(예:ASFF와 유사하게 얕은 레이어를 과도하게 압도하지 않으면서 다중 스케일 피처를 병합하는 적응 가중 융합과 같은 방식mdpi.com), 및 (c) 공의 주변을 포착하기 위해 초기 단계에 팽창 또는 변형 합성곱 층과 같은 문맥 모듈을 도입하는 것mdpi.com. 다운샘플링 과정에서의 정보 손실을 근본적으로 줄이고 작은 물체 특성에 맞게 네트워크를 조정함으로써, 이 모델은 정밀도와 속도 면에서 일반적인 YOLO/Tiny 모델을 능가하는 것을 목표로 한다. 중요한 점은 이러한 변경(얕은 헤드, 융합된 피처 등) 중 다수가 추가 연산 비용이 거의 없다는 것이다 — 예를 들어 SEMA-YOLO의 다중스케일 적응 모듈은 큰 계산 비용 없이 작은 물체 검출을 개선했다mdpi.com. 전반적으로 이 아키텍처는 설계상 경량이며, 필요 시 복잡도를 더 줄이기 위해 Ghost 모듈, 깊이별 분리 합성곱(depthwise separable conv) 등 현대적 기법을 활용하여 모델이 적당한 하드웨어에서 실시간(~30–60 FPS)으로 동작할 수 있도록 한다.



## 2. Specialized Data Augmentation for Ultra High-Speed Objects2. 초고속 객체를 위한 특수 데이터 증강

High-speed projectiles like baseballs or tennis balls require data that reflect their extreme motion patterns. A key contribution can be to devise a **data augmentation strategy specifically for fast-moving small objects**. Traditional augmentation (scaling, rotation, etc.) is insufficient – we need to simulate the **motion blur, trajectory, and appearance** of a tiny object in flight. One approach is inspired by Hiemann _et al._ (2021), who introduced **domain-specific augmentations for ball detection**[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=we%20address%20the%20detection%20of,generalization%20ability%20of%20the%20detection). They generated synthetic training images by **inserting ball images following physical trajectories** into scenes[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach). In our case, we can create sequences where a rendered ball moves across frames with random initial speed, angle, and spin, following a parabolic path under gravity. These synthetic “fast-ball” sequences, when added to training, teach the model to recognize motion-blurred balls at various speeds and distances. Crucially, the augmentation should also produce the _inter-frame_ effects: Hiemann’s work calculated **frame-to-frame difference images** as an extra input channel to highlight moving pixels[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=match%20at%20L760%20the%20network,HSV%20representation%20of%20the%20current)[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=increased%20pixel%20intensity%20appear%20darker,in%20the%20resulting%20difference%20image). We can mimic this by generating pairs/triplets of frames with a moving object and including the computed motion masks during training. This effectively trains the network to utilize motion cues. Their results showed that models using such **“motion augmentation”** significantly improved recall on fast objects[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach).고속 투사체(야구공이나 테니스공 등)는 극단적인 운동 패턴을 반영한 데이터가 필요합니다. 중요한 기여는 빠르게 움직이는 작은 물체에 특화된 데이터 증강 전략을 고안하는 것입니다. 전통적인 증강(스케일링, 회전 등)만으로는 충분하지 않습니다 — 우리는 작은 물체가 비행할 때의 모션 블러, 궤적, 그리고 외형을 시뮬레이션해야 합니다. 한 가지 접근법은 Hiemann 등(2021)에서 영감을 얻은 것으로, 이들은 공 검출을 위한 도메인 특화 증강을 도입했습니다(pmc.ncbi.nlm.nih.gov). 그들은 물리적 궤적을 따르는 공 이미지들을 장면에 삽입해 합성 학습 이미지를 생성했습니다(pmc.ncbi.nlm.nih.gov).우리의 경우에는 렌더링한 공이 무작위 초기 속도, 각도, 스핀을 갖고 중력 하에서 포물선 운동을 하며 프레임을 가로지르는 시퀀스를 만들 수 있습니다. 이러한 합성 “고속 공” 시퀀스를 학습 데이터에 추가하면 다양한 속도와 거리에서의 모션 블러가 있는 공을 모델이 인식하도록 학습시킬 수 있습니다. 특히 증강은 프레임 간 효과도 생성해야 합니다: Hiemann의 연구는 움직이는 픽셀을 강조하기 위해 프레임 간 차이 이미지를 추가 입력 채널로 계산했습니다(pmc.ncbi.nlm.nih.gov). 우리는 움직이는 물체가 있는 프레임의 쌍/삼중구를 생성하고 학습 중에 계산된 모션 마스크를 포함시키는 방식으로 이를 모방할 수 있습니다. 이는 네트워크가 운동 단서를 활용하도록 효과적으로 훈련시킵니다.그들의 결과는 이러한 “모션 증강”을 사용한 모델들이 고속 물체에 대한 재현율을 유의미하게 향상시켰음을 보여주었습니다(pmc.ncbi.nlm.nih.gov).

 

Specific augmentation techniques include: **motion blur simulation** (applying linear blur kernels in the direction of travel to the object), **varying exposure** (to emulate rolling shutter or different shutter speeds capturing the fast object), and **trajectory mixes** (straight-line vs. curved or bouncing trajectories). For instance, Zíta and Prošek (2021) synthesized physically plausible sequences of fast objects with different curvilinear paths to augment their tracker’s training data[openaccess.thecvf.com](https://openaccess.thecvf.com/content/ACCV2022/papers/Zhang_Tracking_Small_and_Fast_Moving_Objects_A_Benchmark_ACCV_2022_paper.pdf#:~:text=col%02lected%20for%20evaluation,implemented%20a%20segmentation%20network). We will similarly randomize trajectories: some with pure gravity arcs, others with spin-induced curves or bounces (for baseball, include Magnus effect or wall bounce if relevant). Additionally, we can augment the **backgrounds** extensively – placing the ball against various stadium or field backgrounds, as well as varying lighting – so the model learns to detect the small object under all conditions. By leveraging a mix of **real video data** (e.g. recorded pitches) and these **physics-based synthetic augmentations**, we expect a robust training set. This addresses the data scarcity of high-speed events and ensures the model generalizes. The augmentation strategy itself constitutes a novel contribution if presented rigorously: we will document how incorporating **special motion frames** and physics-driven synthetic data yields a measurable boost in detection accuracy for fast objects, compared to static augmentations[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach). This can be highlighted as a _new data augmentation paradigm for ultra-fast object detection_.특정 증강 기법에는 다음이 포함됩니다: 모션 블러 시뮬레이션(물체의 이동 방향으로 선형 블러 커널 적용), 노출 변화(롤링 셔터나 빠르게 움직이는 물체를 포착하는 서로 다른 셔터 속도를 모방하기 위함), 궤적 혼합(직선 대 곡선 또는 튕기는 궤적). 예를 들어, Zíta와 Prošek(2021)는 서로 다른 곡선 경로를 갖는 물리적으로 그럴듯한 고속 물체 시퀀스를 합성하여 그들의 트래커 학습 데이터를 증강했습니다(openaccess.thecvf.com). 우리는 마찬가지로 궤적을 무작위화할 것입니다: 일부는 순수한 중력 호(arc), 다른 일부는 회전에 의해 유도된 곡선이나 튕김(야구의 경우 관련이 있다면 마그누스 효과나 벽 튕김 포함)을 가집니다.또한 배경을 광범위하게 증강할 수 있습니다 – 공을 다양한 경기장이나 필드 배경에 배치하고 조명을 변화시켜 모델이 모든 조건에서 작은 물체를 감지하도록 학습시킵니다. 실제 비디오 데이터(예: 녹화된 투구)와 이러한 물리 기반 합성 증강을 혼합하여 활용함으로써 견고한 학습 세트를 기대합니다. 이는 고속 사건의 데이터 부족 문제를 해결하고 모델의 일반화 능력을 보장합니다. 증강 전략 자체는 엄격하게 제시될 경우 새로운 기여가 될 수 있습니다: 특별한 모션 프레임과 물리 기반 합성 데이터를 통합하는 방법이 정적 증강과 비교하여 고속 물체 검출 정확도에 측정 가능한 향상을 어떻게 가져오는지 문서화할 것입니다(pmc.ncbi.nlm.nih.gov).이는 초고속 물체 검출을 위한 새로운 데이터 증강 패러다임으로 강조될 수 있습니다.

## 3. Integrating Physics-Based Reasoning into the Model3. 물리 기반 추론을 모델에 통합하기

A standout academic contribution will be **fusing physics knowledge with deep learning**. Human perception naturally uses physics (we predict where a ball will go); our system can do the same. We consider two levels of integration: **(a)** explicit physics-based modules in the tracking pipeline, and **(b)** embedding physics constraints into the model’s design or loss. For (a), a compelling approach is a **hybrid CNN + motion model tracker**. Singh _et al._ (2025) recently demonstrated this by combining a YOLO detector with a **kinematics-based tracking algorithm** for a fast-moving ball[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=camera,in%20challenging%20scenarios%20such%20as). Their system maintains the object’s state (position, velocity, acceleration) and uses **standard motion equations** (e.g. $s = s_0 + v_0 t - \frac{1}{2} g t^2$ under gravity) to predict future positions[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=kinematics%20motion%20model%20based%20on,Vx0%2C%20Vy0%2C%20Vz0%29%20are). Detected positions are fed into a Kalman-like filter that updates the state, while a **collision module** handles bounces (using coefficient of restitution)[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=4,characterizes%20the%20elasticity%20of%20the). This physics-driven prediction helps **bridge detection gaps and reject outliers**[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=matched%20to%20these%20predicted%20positions,as%20occlusions%20or%20detection%20failures) – if the detector misses a frame or gives a spurious result, the tracker can continue the trajectory smoothly or discard the anomaly. Their results on a fast racquetball showed **70% lower tracking error** than a plain Kalman filter[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=rapid%20direction%20changes,tracking%20of%20chal%02lenging%20small%20objects). We will adopt a similar **physics-informed tracker**: after each frame’s detection, propagate the ball’s state using gravity and drag (if needed), predict the next position, and limit the search region for the detector in the next frame (speeding up detection and reducing false positives). This forms a **closed-loop: detection → physics update → constrained detection**, which is far more robust than independent per-frame detection. The novelty here is in seamlessly integrating a **Newtonian motion model** into a learning-based system, a fusion which prior work shows to improve accuracy under challenging conditions[arxiv.org](https://arxiv.org/html/2312.08650#:~:text=physics%20engine%20that%20allows%20them,laws%20to%20estimate%20their%20trajectory).

물리학 지식을 딥러닝과 융합하는 것이 뛰어난 학문적 기여가 될 것이다. 인간의 지각은 본질적으로 물리를 사용한다(우리는 공이 어디로 갈지 예측한다); 우리 시스템도 동일한 일을 할 수 있다. 우리는 통합의 두 수준을 고려한다: (a) 추적 파이프라인에서의 명시적 물리 기반 모듈, 그리고 (b) 모델 설계나 손실 함수에 물리 제약을 내장하는 것. (a)의 경우, 설득력 있는 접근법은 하이브리드 CNN + 운동 모델 트래커이다. Singh 등(2025)은 최근 YOLO 검출기와 운동학 기반 추적 알고리즘을 결합하여 빠르게 움직이는 공을 처리하는 것을 시연했다arxiv.org. 그들의 시스템은 물체의 상태(위치, 속도, 가속도)를 유지하고 표준 운동 방정식(예: 중력 하에서 s = s_0 + v_0 t - \frac{1}{2} g t^2 등)을 사용해 미래 위치를 예측한다arxiv.org. 검출된 위치는 상태를 갱신하는 칼만 유사 필터로 입력되고, 충돌 모듈은 반발 계수를 사용해 튐을 처리한다arxiv.org. 이러한 물리 기반 예측은 검출 공백을 메우고 이상치를 배제하는 데 도움을 준다arxiv.org – 검출기가 프레임을 놓치거나 잘못된 결과를 내더라도 트래커는 궤적을 매끄럽게 이어가거나 이상값을 버릴 수 있다.빠른 라켓볼에 대한 그들의 결과는 단순 칼만 필터보다 추적 오차가 70% 낮음을 보였다arxiv.org. 우리는 유사한 물리 정보 기반 트래커를 채택할 것이다: 각 프레임의 검출 후 공의 상태를 중력과 저항(필요 시)을 사용해 전파하고, 다음 위치를 예측하며 다음 프레임에서 검출기의 탐색 영역을 제한한다(검출 속도 향상 및 오탐 감소). 이것은 닫힌 루프를 형성한다: 검출 → 물리 업데이트 → 제약된 검출, 이는 프레임별 독립 검출보다 훨씬 더 견고하다. 여기서의 새로움은 뉴턴 운동 모델을 학습 기반 시스템에 원활하게 통합하는 데 있으며, 이전 연구들은 이러한 융합이 어려운 조건에서 정확도를 향상시킨다는 것을 보여준다arxiv.org.



 

For (b), we can imbue the deep model itself with physics awareness. One idea is a multi-task network that **outputs both the object’s detection and its velocity vector** (or parameters of its trajectory). By training the network to predict velocity (using differences between consecutive frame truths as supervision), we essentially give it a sense of motion. These predicted velocities can be fed into a small **neural physics module** (perhaps implemented as a differentiable layer) that projects the position into the next frame. A **physical consistency loss** can be applied: e.g. penalize the difference between the network’s predicted next position and the actual detected next position, encouraging consistency with constant-acceleration motion. Such physics-informed losses have been used in other domains (e.g. human motion modeling) to ensure trajectories obey realistic dynamics[nature.com](https://www.nature.com/articles/s41598-025-26972-4?error=cookies_not_supported&code=412a57bb-0d0f-4576-b3f3-8c7bbb02ddbc#:~:text=,related%20applications). In our context, incorporating **gravity as a known constant** in the trajectory calculation is straightforward (the $- \frac{1}{2}gt^2$ term for vertical drop). During training, we can simulate partial trajectories and require the model to continue them realistically. Another angle is using **optical flow** as input: as shown in PhyOT (2023), treating neural networks as “sensors” in a Kalman Filter and using optical flow to estimate velocity improved tracking in difficult scenarios[arxiv.org](https://arxiv.org/html/2312.08650#:~:text=We%20consider%20the%20case%20of,a%20traffic%20camera%20open%20dataset)[arxiv.org](https://arxiv.org/html/2312.08650#:~:text=that%20conceptualizes%20deep%20neural%20networks,a%20traffic%20camera%20open%20dataset). We could similarly feed the network a stack of frames or an optical flow map, enabling it to infer motion implicitly. The ultimate design might be a **hybrid architecture**: a CNN backbone for detection, a parallel module (CNN or RNN) taking frame differences to predict acceleration/velocity, and a fusion module (like a Kalman update) to combine them. This would directly embed a **learned physics engine** alongside detection. Academically, this is novel because it moves beyond treating object detection as a static image problem and towards a **physics-informed vision model**. We will justify that our approach provides more **interpretable and stable predictions**, as it marries data-driven learning with well-understood physical laws – an idea supported by recent literature bridging deep learning and physics for vision tasks[arxiv.org](https://arxiv.org/html/2312.08650#:~:text=physics%20engine%20that%20allows%20them,laws%20to%20estimate%20their%20trajectory)[nature.com](https://www.nature.com/articles/s41598-025-26972-4?error=cookies_not_supported&code=412a57bb-0d0f-4576-b3f3-8c7bbb02ddbc#:~:text=Building%20on%20the%20limitations%20of,conditions%20such%20as%20occlusions%20and).

(b)의 경우 심층 모델 자체에 물리 인식을 부여할 수 있습니다. 한 가지 아이디어는 물체의 검출 결과와 속도 벡터(또는 궤적의 파라미터)를 동시에 출력하는 다중 작업 네트워크입니다. 연속 프레임 간의 실제값 차이를 감독 신호로 사용해 네트워크가 속도를 예측하도록 학습시키면 본질적으로 운동 감각을 부여하는 셈입니다. 이렇게 예측된 속도는 작은 신경물리 모듈(아마도 미분 가능 층으로 구현될 수 있음)에 입력되어 다음 프레임으로 위치를 투사할 수 있습니다. 물리적 일관성 손실을 적용할 수 있습니다. 예를 들어 네트워크가 예측한 다음 위치와 실제로 검출된 다음 위치의 차이를 벌칙으로 하여 등가속도 운동과의 일관성을 장려하는 식입니다. 이러한 물리 정보 기반 손실은 인간 운동 모델링 등 다른 분야에서도 궤적이 현실적인 역학을 따르도록 하기 위해 사용되어 왔습니다(nature.com). 우리의 맥락에서는 궤적 계산에 중력 값을 알려진 상수로 포함하는 것이 간단합니다(수직 낙하에 대한 -1/2 g t^2 항). 학습 중에는 부분 궤적을 시뮬레이션하고 모델이 이를 현실적으로 이어가도록 요구할 수 있습니다.또 다른 관점은 입력으로 광류(optical flow)를 사용하는 것입니다. PhyOT(2023)에서 보인 것처럼 신경망을 칼만 필터의 “센서”로 취급하고 광류로 속도를 추정하면 어려운 상황에서 추적이 개선되었습니다(arxiv.org arxiv.org). 마찬가지로 네트워크에 프레임 스택이나 광류 맵을 입력하여 운동을 암묵적으로 유추하게 할 수 있습니다. 궁극적 설계는 하이브리드 아키텍처일 수 있습니다. 검출을 위한 CNN 백본, 프레임 차이를 받아 가속도/속도를 예측하는 병렬 모듈(CNN이나 RNN), 그리고 이를 결합하는 융합 모듈(칼만 업데이트와 유사)을 두는 식입니다. 이렇게 하면 학습된 물리 엔진이 검출과 함께 직접 내장됩니다. 학문적으로 이는 물체 검출을 정적 이미지 문제로 다루는 것을 넘어 물리 정보가 반영된 비전 모델로 나아간다는 점에서 새롭습니다. 우리의 접근법은 데이터 기반 학습과 잘 이해된 물리 법칙을 결합하여 더 해석 가능하고 안정적인 예측을 제공한다는 점을 입증할 것이며—이 아이디어는 딥러닝과 물리를 연결한 최근 문헌들이 비전 과제에 대해 뒷받침합니다(arxiv.org nature.com).

## 4. Beyond YOLO: Trajectory-Aware Detection and Tracking Algorithm4. YOLO를 넘어서: 궤적 인지 검출 및 추적 알고리즘

Simply improving a YOLO model may not fully solve our problem; we also need a new **algorithmic approach for detection+tracking** that overcomes YOLO’s limitations. Traditional YOLO (even Tiny versions) performs one-frame-at-a-time detection without memory. Our strategy instead treats it as a **temporal detection problem**. We propose a **Trajectory-Aware YOLO Tracker**: essentially, integrate object detection with a tracking algorithm so they reinforce each other. One component is using the physics-informed tracker (from section 3) to guide the detector each frame. Another is incorporating techniques from modern tracking-by-detection research. For instance, sequential linking methods like **Seq-NMS** can be applied to smooth detection outputs by increasing the confidence of consistent consecutive detections[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=architecture%20of%20the%20detection%20network,detections%20and%20to%20stabilize%20the). More ambitiously, we draw inspiration from **KalmanFormer** (Qin _et al._, 2025), which augments the SORT tracking algorithm with deep learning to handle non-linear motion[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=occlusions.%20Although%20conventional%20Kalman,boosting%20object%20association%20under%20occlusions)[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=To%20address%20the%20aforementioned%20limitations%2C,The). They use a small transformer network to learn corrections to the Kalman filter’s linear motion assumption, and even generate “virtual detections” when the detector misses an object[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=motion%20assumption,stabilizing%20the%20Kalman%20filter%20update)[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=To%20address%20the%20aforementioned%20limitations%2C,captures%20interactions%20across%20object). In our case, the ball’s motion can be non-linear (curveballs, bounces), so a learned motion corrector is valuable. We could implement a lightweight **trajectory predictor network** trained on real and synthetic flight paths to adjust the physics model when needed (similar to KalmanFormer’s residual learning of motion[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=occlusions.%20Although%20conventional%20Kalman,trajectory%20attention%20module%20captures%20interobject)). Furthermore, if a frame has _no detection_ (e.g. due to occlusion or motion blur), our system can rely on the predicted position from physics to **insert a pseudo-detection**, preventing track loss (this is analogous to KalmanFormer’s pseudo-observation generator[mdpi.com](https://www.mdpi.com/2076-3417/15/17/9727#:~:text=Kalman%20filter%20predictions%20by%20learning,The%20experimental%20results%20on%20the)). By coupling detection with such a smart tracker, the **algorithm goes beyond YOLO’s frame-by-frame paradigm** – it essentially performs **online trajectory estimation**.간단히 YOLO 모델만 개선한다고 해서 문제가 완전히 해결되지는 않을 수 있으며, 우리는 YOLO의 한계를 극복하는 검출+추적을 위한 새로운 알고리즘적 접근도 필요하다. 전통적인 YOLO(심지어 Tiny 버전도)는 메모리 없이 프레임을 하나씩 처리하는 검출을 수행한다. 대신 우리의 전략은 이를 시간적(temporal) 검출 문제로 다루는 것이다. 우리는 궤적 인지형(trajectory-aware) YOLO 트래커를 제안한다: 본질적으로 객체 검출을 추적 알고리즘과 통합하여 서로를 보강하게 한다. 한 구성 요소는 (3절의) 물리 기반 트래커를 각 프레임의 검출기를 안내하도록 사용하는 것이다. 다른 구성 요소는 최신 tracking-by-detection 연구에서 나온 기법들을 도입하는 것이다. 예를 들어 Seq-NMS 같은 연속 연결 방법은 일관된 연속 검출의 신뢰도를 높여 검출 출력을 부드럽게 만드는 데 적용할 수 있다(pmc.ncbi.nlm.nih.gov). 보다 야심차게는, 우리는 KalmanFormer(Qin et al., 2025)에서 영감을 얻었다. 이 연구는 SORT 추적 알고리즘을 딥러닝으로 확장해 비선형 운동을 다루게 한다(mdpi.com). 그들은 작은 트랜스포머 네트워크를 사용해 칼만 필터의 선형 운동 가정에 대한 보정을 학습하고, 검출기가 객체를 놓칠 때 “가상 검출(virtual detections)”을 생성하기도 한다(mdpi.com). .com. 우리 경우 공의 움직임은 비선형(커브볼, 바운스 등)일 수 있으므로, 학습된 운동 보정기는 유용하다. 우리는 실제 및 합성 비행 궤적으로 학습된 경량의 궤적 예측기 네트워크를 구현해 필요할 때 물리 모델을 조정할 수 있다(KalmanFormer의 잔차 학습과 유사하게, mdpi.com). 더 나아가 한 프레임에 검출이 없을 경우(예: 가림이나 모션 블러로 인해) 시스템은 물리 예측 위치에 의존해 의사 검출(pseudo-detection)을 삽입함으로써 트랙 손실을 방지할 수 있다(이는 KalmanFormer의 의사 관측 생성기와 유사하다, mdpi.com). 이처럼 검출을 이러한 스마트 트래커와 결합하면 알고리즘은 YOLO의 프레임별 패러다임을 넘어선다 — 본질적으로 온라인 궤적 추정을 수행하게 된다.

 

We also consider that YOLO’s standard anchor-based detection might miss very small objects or those with extreme aspect ratios. Anchor-free detectors (like **FoveaBox**[openaccess.thecvf.com](https://openaccess.thecvf.com/content/ACCV2022/papers/Zhang_Tracking_Small_and_Fast_Moving_Objects_A_Benchmark_ACCV_2022_paper.pdf#:~:text=32,A%20novel%20performance%20evaluation%20methodology) or newer **DETR variants**) could be explored as alternatives, since they do not rely on predefined anchor sizes. For example, a transformer-based detector could use global attention to find the small object in the wide field, potentially leveraging context better. However, many transformer detectors are too slow for our real-time needs, so our strategy focuses on augmenting a fast CNN detector with temporal logic. The **novel algorithmic contribution** is the unification of **detection, temporal continuity, and physical modeling** into one framework. This means our system is continuously verifying: “Did the detection align with the predicted trajectory? If not, should we correct the trajectory or was the detection false?” – a level of reasoning absent in standard YOLO. This closed-loop approach aims to **minimize false negatives** (the tracker will anticipate the object even if detection confidence is low) and **reduce false positives** (erroneous detections that don’t fit the trajectory are ignored or corrected[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=matched%20to%20these%20predicted%20positions,as%20occlusions%20or%20detection%20failures)). It effectively blurs the line between detection and tracking, treating them as a single problem of **trajectory detection**. In academic terms, this can be framed as a new **real-time small object tracking algorithm**. We will show that it outperforms naive YOLO or Kalman filter baselines on metrics like tracking accuracy (e.g. Average Displacement Error[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=rapid%20direction%20changes,tracking%20of%20chal%02lenging%20small%20objects)) and detection precision/recall, especially under fast motion and occlusion.우리는 또한 YOLO의 표준 앵커 기반 검출이 매우 작은 객체나 극단적인 종횡비를 가진 객체를 놓칠 수 있음을 고려한다. 사전 정의된 앵커 크기에 의존하지 않는 앵커 프리 검출기(예: FoveaBoxopenaccess.thecvf.com 또는 최신 DETR 변형)를 대안으로 탐색할 수 있다. 예를 들어, 트랜스포머 기반 검출기는 전역 어텐션을 이용해 넓은 시야에서 작은 객체를 찾아내어 문맥을 더 잘 활용할 수 있다. 그러나 많은 트랜스포머 검출기는 우리의 실시간 요구사항에는 너무 느리기 때문에, 우리의 전략은 빠른 CNN 검출기에 시간적 논리를 보강하는 데 중점을 둔다. 알고리즘적 새 기여는 검출, 시간적 연속성, 물리적 모델링을 하나의 프레임워크로 통합한 것이다. 이는 우리 시스템이 지속적으로 다음을 검증함을 의미한다: “검출이 예측된 궤적과 일치했는가? 그렇지 않다면 궤적을 수정해야 하는가, 아니면 검출이 잘못된 것이었는가?” — 이는 표준 YOLO에는 없는 수준의 추론이다. 이 폐쇄 루프 접근법은 거짓 음성(false negatives)을 최소화하는 것을 목표로 한다(추적기는 검출 신뢰도가 낮더라도 객체를 예상할 것임)와 거짓 양성(false positives)을 줄이는 것을 목표로 한다(궤적에 맞지 않는 잘못된 검출은 무시되거나 수정된다)arxiv.org). 이는 검출과 추적의 경계를 효과적으로 흐리게 하여 이를 궤적 검출의 단일 문제로 취급한다. 학술적으로는 이를 새로운 실시간 소형 객체 추적 알고리즘으로 표현할 수 있다. 우리는 이것이 추적 정확도(예: 평균 변위 오차Average Displacement Errorarxiv.org)와 검출 정밀도/재현율 같은 지표에서, 특히 빠른 움직임과 가림 현상(occlusion) 하에서 단순한 YOLO나 칼만 필터 기반 기준보다 우수함을 보여줄 것이다.

## Integration and Novelty통합 및 새로움

By integrating the above elements, we envision a **unified system architecture** (and corresponding paper) that could be positioned as _“Physically Inspired Real-Time Detection and Tracking for Fast Small Objects.”_ The novelty lies in the **holistic design**: while prior works address individual aspects (small-object CNN improvements[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=fusion%20mechanism%2C%20the%20proposed%20framework,C3k2%20structure%2C%20is%20introduced%20to), or physics-based trackers[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=camera,in%20challenging%20scenarios%20such%20as), or data augmentation[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach)), _none_ have combined all into a single framework for a specific real-world problem (AR strike zone). Our proposed system would, for the first time, demonstrate that **carefully fusing model efficiency, data realism, and physical priors yields a substantial leap in performance** for high-speed object tracking. We will articulate novelty in the paper much like others do: by enumerating contributions. For example, we might write – “**Contributions:** (1) A novel lightweight architecture for fast tiny-object detection, (2) a physics-guided data augmentation strategy for high-speed objects, (3) a hybrid physics-aware tracking method integrated into the deep model, and (4) a unified real-time system that significantly outperforms existing YOLO-based methods on small, fast-moving object benchmarks.” We will back these claims with ablation studies: e.g., show how each component (architecture tweak, augmentation, physics module) improves results, to validate that the integration indeed provides an academic contribution. Referencing similar integrated approaches in other domains (like physics-informed pose estimation which improved accuracy and interpretability[nature.com](https://www.nature.com/articles/s41598-025-26972-4?error=cookies_not_supported&code=412a57bb-0d0f-4576-b3f3-8c7bbb02ddbc#:~:text=,related%20applications)) will strengthen our case that mixing deep learning with domain knowledge is a valuable innovation.위 요소들을 통합하여 우리는 “고속 소형 물체를 위한 물리 기반 실시간 검출 및 추적”로 포지셔닝할 수 있는 통합 시스템 아키텍처(및 이에 대응하는 논문)를 구상합니다. 참신성은 전체론적 설계에 있습니다: 이전 연구들은 개별 측면들(소형 물체 CNN 개선 mdpi.com, 혹은 물리 기반 추적기 arxiv.org, 혹은 데이터 증강 pmc.ncbi.nlm.nih.gov)을 다루었지만, 특정 실제 문제(AR 스트라이크 존)를 위해 이 모든 것을 단일 프레임워크로 결합한 사례는 없습니다. 우리가 제안하는 시스템은 모델 효율성, 데이터 현실성, 물리적 사전지식을 신중하게 융합하면 고속 물체 추적 성능에서 상당한 도약을 이룰 수 있음을 처음으로 보여줄 것입니다. 우리는 다른 논문들처럼 기여사항을 열거하는 방식으로 논문에서 참신성을 명확히 밝힐 것입니다.예를 들어 우리는 이렇게 쓸 수 있습니다 — “기여사항: (1) 고속의 초소형 물체 검출을 위한 새로운 경량 아키텍처, (2) 고속 물체를 위한 물리 지향 데이터 증강 전략, (3) 딥 모델에 통합된 하이브리드 물리 인지 추적 방법, 및 (4) 소형 고속 이동 물체 벤치마크에서 기존의 YOLO 기반 방법들을 능가하는 통합 실시간 시스템.” 우리는 각 구성요소(아키텍처 조정, 증강, 물리 모듈)가 어떻게 결과를 향상시키는지 보여주는 제거 실험(ablation study)으로 이러한 주장을 뒷받침할 것입니다. 다른 분야에서의 유사한 통합 접근법(정확도와 해석가능성을 향상시킨 물리 정보 기반 포즈 추정 등 nature.com)을 참조하는 것은 딥러닝과 도메인 지식을 혼합하는 것이 가치있는 혁신이라는 우리의 주장을 강화할 것입니다.

## Research Implementation Roadmap연구 실행 로드맵

To translate this strategy into practice, we outline a **step-by-step research plan**:이 전략을 실무에 적용하기 위해, 단계별 연구 계획을 제시합니다:

 

**Stage 0: Data Collection & Benchmark Setup.** First, we will curate a dataset for our task. This includes **recorded high-speed video** of the object (e.g. many baseball pitches, possibly using a 120+ FPS camera for better ground truth) and labeling the object’s pixel coordinates per frame. We will supplement real data with **synthetic data generation** as described: rendering a ball on various backgrounds with randomized trajectories. We’ll split data into training, validation, test sets across diverse conditions. Additionally, we’ll establish evaluation metrics: **detection mAP** (especially mAP for small objects), precision/recall, and **tracking metrics** like MOTA (Multiple Object Tracking Accuracy, though single object here, it reduces to tracking accuracy) and Average Displacement Error[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=rapid%20direction%20changes,tracking%20of%20chal%02lenging%20small%20objects). Having a defined benchmark (perhaps we create a “FastBall 2025” dataset) also adds academic value.단계 0: 데이터 수집 및 벤치마크 설정. 먼저 우리 과제에 맞는 데이터셋을 선별합니다. 여기에는 물체의 고속 비디오 녹화(예: 더 정확한 실제 정답을 위해 120 FPS 이상의 카메라로 촬영한 많은 야구 투구들)와 프레임별 물체의 픽셀 좌표 라벨링이 포함됩니다. 우리는 다음과 같이 설명한 합성 데이터 생성을 통해 실제 데이터를 보완할 것입니다: 다양한 배경 위에 공을 렌더링하고 궤적을 무작위화합니다. 데이터를 다양한 조건에 걸쳐 학습, 검증, 테스트 세트로 분할합니다. 또한 평가 지표를 설정할 것입니다: 검출 mAP(특히 작은 물체에 대한 mAP), 정밀도/재현율, 그리고 MOTA(다중 물체 추적 정확도 — 여기서는 단일 물체이므로 추적 정확도로 축소됨)와 Average Displacement Error 같은 추적 지표를 포함합니다. 정의된 벤치마크(아마도 “FastBall 2025” 데이터셋을 만들 수도 있음)를 갖추는 것은 학문적 가치도 더해줍니다.

 

**Stage 1: Baseline Experiments.** We begin with baseline models to quantify the starting point. For example, train a standard YOLOv8 or YOLO-Nano on our dataset (with minimal augmentation) to get a baseline AP and speed. Also test a naive tracker (YOLO + Kalman filter with constant velocity) to get baseline tracking error. These will highlight the gaps (e.g. YOLO might miss many frames or have low AP on the fast object, and the tracker might break on curves). Documenting these results provides motivation for our contributions.1단계: 기본 실험. 출발점을 정량화하기 위해 기본 모델로 시작합니다. 예를 들어, 최소한의 증강으로 우리 데이터셋에서 표준 YOLOv8 또는 YOLO-Nano를 학습시켜 기준 AP와 속도를 얻습니다. 또한 기본 트래커(상수 속도의 칼만 필터를 결합한 YOLO)를 테스트하여 기준 추적 오차를 구합니다. 이러한 결과는 격차를 부각시켜 줍니다(예: YOLO가 많은 프레임을 놓치거나 빠른 물체에 대해 AP가 낮을 수 있고, 트래커는 곡선 구간에서 깨질 수 있음). 이러한 결과들을 문서화하는 것은 우리의 기여를 정당화하는 근거가 됩니다.

 

**Stage 2: Model Development – Iterative Enhancements.** We will incrementally implement the components of our approach, each time evaluating improvement:2단계: 모델 개발 – 점진적 개선. 우리는 접근 방식의 구성 요소들을 단계적으로 구현하고 그때마다 개선 효과를 평가할 것입니다:

- **Architecture refinement:** Implement the Tiny-StrikeNet with shallow-layer detection head and context modules. Use the same training data and compare detection accuracy vs. baseline YOLO. We expect to see higher recall on small objects due to the specialized architecture (similar to gains reported by SEMA-YOLO[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=achieve%20more%20refined%20feature%20extraction,art%20models)[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=Receptive%20Field%20Attention%20Convolution%20Module,and%20sensitivity%20to%20small%20objects)). We’ll optimize this model’s size so that it runs in realtime (e.g. by pruning unnecessary layers or channels if needed, or using MobileNet-v3 backbone as a base for efficiency).아키텍처 정제: 얕은 레이어 검출 헤드와 컨텍스트 모듈을 갖춘 Tiny-StrikeNet을 구현하세요. 동일한 학습 데이터를 사용하고 기준 모델인 YOLO와 검출 정확도를 비교하세요. 전문화된 아키텍처 때문에 작은 물체에 대한 재현율(recall)이 더 높아질 것으로 예상합니다(예: SEMA-YOLO에서 보고된 향상과 유사). 이 모델의 크기를 실시간으로 동작할 수 있도록 최적화할 예정입니다(필요 시 불필요한 레이어나 채널을 프루닝하거나 효율성을 위해 MobileNet-v3 백본을 기본으로 사용하는 등).
    
- **Data augmentation study:** Introduce the physics-based augmentations into training. We conduct an ablation: train the model with and without motion augmentations and compare performance on a held-out test of high-speed scenarios. We anticipate a noticeable boost in generalization when motion augments are included[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach). We will carefully analyze failure cases (does the model still struggle with certain angles or lighting?) to inform any augment tweaks.데이터 증강 연구: 물리 기반 증강을 훈련에 도입합니다. 우리는 제거 실험을 수행합니다: 모션 증강을 사용한 경우와 사용하지 않은 경우로 모델을 훈련시키고 고속 시나리오의 별도 보류 테스트에서 성능을 비교합니다. 모션 증강을 포함하면 일반화에서 눈에 띄는 향상이 있을 것으로 예상합니다pmc.ncbi.nlm.nih.gov. 우리는 실패 사례를 면밀히 분석할 것입니다(모델이 특정 각도나 조명에서 여전히 어려움을 겪는가?) 증강 조정에 반영하기 위해서입니다.
    
- **Physics integration:** Develop the tracking module that consumes detections. We might start with a simple KF+gravity model, then add complexity. We will test the tracking performance (e.g. how often does it lose the ball? average error of trajectory prediction). If using a learned motion model (like a small neural network to adjust the physics), we will train it on trajectory data (possibly using synthetic trajectories for ground truth). One way to train is to simulate dropping or throwing motions and have the network predict the next position given the current state – essentially learning to emulate physics, which can then correct the real physics model when the ball has spin or drag that our simple equations don’t capture.물리 통합: 검출을 소비하는 추적 모듈을 개발합니다. 간단한 칼만 필터+중력 모델로 시작한 뒤 점차 복잡성을 추가할 수 있습니다. 추적 성능(예: 공을 얼마나 자주 놓치는지, 궤적 예측의 평균 오차)을 테스트할 것입니다. 학습된 운동 모델(물리 보정을 위한 작은 신경망 등)을 사용하는 경우 궤적 데이터(가능하면 합성 궤적을 정답으로 사용)를 가지고 학습시킬 것입니다. 학습 방법 중 하나는 떨어뜨리기나 던지기 동작을 시뮬레이션하고 네트워크가 현재 상태를 주면 다음 위치를 예측하도록 하는 것인데, 본질적으로 물리를 모방하도록 학습시켜 공에 회전이나 항력 같은 단순 방정식으로는 잡아내지 못하는 효과가 있을 때 실제 물리 모델을 보정할 수 있도록 하는 것입니다.
    
- **Algorithmic fusion:** Combine the detection and tracking into one pipeline and evaluate end-to-end. This means measuring final metrics like “overall system precision”: e.g., was the ball correctly detected and continuously tracked through an entire pitch? We will compare this against the baseline tracker. We expect to see improvements such as: fewer frames where the ball is missed (due to predictive tracking bridging gaps) and less jitter in the reported trajectory (due to physical smoothing). We’ll also ensure latency is still low – possibly using a frame-by-frame processing time breakdown.알고리즘적 통합: 탐지와 추적을 하나의 파이프라인으로 결합하여 엔드투엔드로 평가합니다. 이는 “전체 시스템 정밀도”와 같은 최종 지표를 측정한다는 뜻입니다. 예: 공이 제대로 탐지되어 경기 전체에 걸쳐 연속적으로 추적되었는가? 이를 기준 추적기와 비교할 것입니다. 우리는 다음과 같은 개선을 기대합니다: 공이 놓치는 프레임 수 감소(예측 추적로 공백을 보완함으로써) 및 보고된 궤적의 떨림 감소(물리적 평활화로 인해). 또한 지연이 여전히 낮은지 확인할 것이며 — 필요하다면 프레임별 처리 시간 분해를 사용할 수 있습니다.
    

Throughout Stage 2, we’ll carry out **comparative experiments** with existing methods. For instance, we can compare against the approach in Hiemann et al.[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=we%20address%20the%20detection%20of,generalization%20ability%20of%20the%20detection) (YOLOv3 with motion channel) on a similar sports video to see if our new model achieves higher accuracy or speed. If possible, we also evaluate on any public benchmark for small fast objects (the **TSFMO** benchmark[openaccess.thecvf.com](https://openaccess.thecvf.com/content/ACCV2022/papers/Zhang_Tracking_Small_and_Fast_Moving_Objects_A_Benchmark_ACCV_2022_paper.pdf#:~:text=4%20Z,50%5D%20to) might be relevant if available) to show broad applicability.2단계 전반에 걸쳐 기존 방법들과 비교 실험을 수행할 것입니다. 예를 들어, 유사한 스포츠 영상에서 Hiemann et al.의 접근법(pmc.ncbi.nlm.nih.gov; 모션 채널을 포함한 YOLOv3)과 비교하여 우리 새 모델이 더 높은 정확도나 속도를 달성하는지 확인할 수 있습니다. 가능하다면 소형 고속 객체에 대한 공개 벤치마크(이 경우 이용 가능하다면 TSFMO 벤치마크(openaccess.thecvf.com)가 관련될 수 있음)에서도 평가하여 광범위한 적용 가능성을 입증합니다.

 

**Stage 3: Optimization and Deployment Considerations.** With a working model, we will apply optimizations for real deployment. This includes techniques like **TensorRT acceleration** (as used by Hiemann _et al._ to achieve real-time speeds[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=In%20order%20to%20use%20the,of%20TensorRT%2C%20we%20are%20forced)) or model quantization to speed up inference on AR devices. We’ll verify that after optimization, the accuracy does not drop significantly. We will also test the system in an actual AR context: e.g., overlay the detected strike zone and ball trajectory on a video feed to ensure the latency is low and the visualization is correct. This stage, while more engineering, provides evidence that our research can be **practically applied** – a valuable point for both academic and industry impact.3단계: 최적화 및 배포 고려사항. 작동하는 모델을 확보한 후 실제 배포를 위해 최적화를 적용합니다. 여기에는 Hiemann 등(실시간 속도를 달성하기 위해 사용한)에서 사용된 TensorRT 가속(spmc.ncbi.nlm.nih.gov)이나 AR 기기에서 추론 속도를 높이기 위한 모델 양자화와 같은 기법들이 포함됩니다. 최적화 후 정확도가 크게 저하되지 않는지 검증할 것입니다. 또한 실제 AR 환경에서 시스템을 테스트할 것입니다. 예를 들어, 감지된 스트라이크 존과 공의 궤적을 비디오 피드에 오버레이하여 지연 시간이 낮고 시각화가 올바른지 확인합니다. 이 단계는 공학적 작업이 더 많지만 우리의 연구가 실제로 적용될 수 있다는 증거를 제공하며—학계와 산업계 모두에 중요한 포인트입니다.

 

**Stage 4: Evaluation of Academic Contribution.** Finally, we compile the results and novel insights. We’ll create visualizations (plots of trajectories, images of detection vs. ground truth, etc.) to illustrate how the integration of physics and learning works. For example, showing a sequence where a naive model loses the ball but our physics-guided model keeps locking onto it through a bounce would powerfully demonstrate our system’s advantage. We will also quantify trade-offs (e.g. how much latency the physics module adds, which should be minimal). In writing the research paper or report, we emphasize the **interdisciplinary novelty** – e.g. _“Our work bridges computer vision and physics modeling, demonstrating that a hybrid approach outperforms purely data-driven or purely model-driven methods for fast object tracking.”_ We also candidly discuss limitations (perhaps extremely unpredictable aerodynamic effects might still pose challenges) and outline future extensions (like using event camera input for even faster motions, or applying our framework to other sports like tennis or even non-sports fast objects).4단계: 학문적 기여의 평가. 마지막으로 결과와 새로운 통찰을 종합합니다. 통합된 물리학과 학습의 작동 방식을 설명하기 위해 시각화(궤적 플롯, 검출 대 실제 대비 이미지 등)를 만듭니다. 예를 들어, 순진한 모델이 공을 놓치는 장면과 반면에 우리 물리 기반 모델이 바운스 동안에도 공을 계속 추적하는 연속 장면을 보여주는 것은 우리 시스템의 장점을 강력하게 증명할 것입니다. 또한 물리 모듈이 추가하는 지연(latency)이 얼마나 되는지와 같이 트레이드오프를 정량화합니다(지연은 최소화되어야 합니다). 연구 논문이나 보고서를 작성할 때는 학제 간의 새로움을 강조합니다 — 예: “우리의 연구는 컴퓨터 비전과 물리 모델링을 연결하여 혼합 접근법이 순수 데이터 기반 또는 순수 모델 기반 방법보다 빠른 물체 추적에서 우수함을 입증한다.” 또한 한계점(아주 예측 불가능한 공기역학적 영향이 여전히 문제를 일으킬 수 있음 등)을 솔직히 논의하고, 향후 확장 방안(더 빠른 움직임을 위해 이벤트 카메라 입력을 사용하거나 테니스 같은 다른 스포츠나 비스포츠의 빠른 물체에 우리 프레임워크를 적용하는 것 등)을 제시합니다.

 

By following this roadmap, we not only implement the system step-by-step but also generate a comprehensive **evaluation of each proposed idea** (each of which can be an academic contribution on its own). This ensures that the final outcome is a thoroughly validated, novel solution for AR strike zone tracking. Such a solution would advance the state of the art in **small object detection and tracking**, with potential application in sports analytics, surveillance (e.g. tracking flying drones or projectiles), and any scenario involving **fast, tiny targets** that current vision systems struggle with. Each of the design decisions – from architecture to augmentation to physics integration – will be justified with references to literature and our own empirical results, solidifying the work as an academically sound contribution.이 로드맵을 따르면 시스템을 단계적으로 구현할 뿐만 아니라 제안된 각 아이디어(각 아이디어가 그 자체로 학문적 기여가 될 수 있음)에 대한 포괄적인 평가도 생성합니다. 이는 최종 결과물이 AR 스트라이크 존 추적을 위한 철저히 검증된 새로운 솔루션임을 보장합니다. 이러한 솔루션은 작은 물체 검출 및 추적의 최첨단을 진전시켜 스포츠 분석, 감시(예: 비행 드론이나 투사체 추적) 및 현재 비전 시스템이 어려움을 겪는 빠르고 작은 표적이 있는 모든 시나리오에 적용될 수 있습니다. 아키텍처에서 증강, 물리학 통합에 이르기까지 각 설계 결정은 문헌 참고와 우리의 실험적 결과로 정당화되어 이 연구를 학술적으로 타당한 기여로 확고히 할 것입니다.

 

**References:** The strategy draws upon recent advances in small object detection (e.g. shallow-layer enhanced networks[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=fusion%20mechanism%2C%20the%20proposed%20framework,C3k2%20structure%2C%20is%20introduced%20to)[mdpi.com](https://www.mdpi.com/2072-4292/17/11/1917#:~:text=Receptive%20Field%20Attention%20Convolution%20Module,and%20sensitivity%20to%20small%20objects), dilated context fusion[mdpi.com](https://www.mdpi.com/2076-3417/15/22/11882#:~:text=model%20architecture%2C%20e,more%20contextual%20information%20around%20suspected)), domain-specific data augmentation for fast objects[pmc.ncbi.nlm.nih.gov](https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/#:~:text=calculating%20the%20difference%20images%20for,the%20ball%20movements%20in%20beach), and physics-informed tracking algorithms[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=kinematics%20motion%20model%20based%20on,Vx0%2C%20Vy0%2C%20Vz0%29%20are)[arxiv.org](https://arxiv.org/pdf/2510.20126#:~:text=camera,in%20challenging%20scenarios%20such%20as). By synthesizing these insights into one framework, the research will push the envelope of what’s possible in real-time AR object tracking. All source references used (marked in **【】**) point to the supporting literature for each component of the proposed approach, underscoring the plan’s foundation in proven concepts while highlighting its novel combinations.참고문헌: 이 전략은 소형 물체 검출의 최신 발전(예: 얕은 층 강화 네트워크 mdpi.commdpi.com, 팽창된 컨텍스트 융합 mdpi.com), 빠른 물체를 위한 도메인 특화 데이터 증강 pmc.ncbi.nlm.nih.gov, 물리 기반 추적 알고리즘 arxiv.orgarxiv.org 등에서 아이디어를 차용합니다. 이러한 통찰을 하나의 프레임워크로 통합함으로써 본 연구는 실시간 AR 객체 추적에서 가능한 한계를 확장할 것입니다. 사용된 모든 출처 참조(【】로 표시됨)는 제안된 접근 방식의 각 구성 요소를 뒷받침하는 문헌을 가리키며, 입증된 개념에 기반한 계획임을 강조하는 동시에 그 참신한 조합을 부각합니다.