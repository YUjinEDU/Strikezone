# ğŸ¯ AR Strike Zone êµ¬í˜„ ê°€ì´ë“œ - Part 2

> **Part 1 ì´ì–´ì„œ**: ì„œë²„/ì›¹, ë¬¼ë¦¬ ê¸°ë°˜ ì¶”ì , ë°ì´í„° ì¦ê°•, ì°¸ê³  ë…¼ë¬¸

---

## 5. Phase 3: ì„œë²„ ë° ì›¹ ëŒ€ì‹œë³´ë“œ (3-4ì£¼)

### 5.1 ì„œë²„ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend Server                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ FastAPI  â”‚â”€â”€â”€â”€â–¶â”‚  Redis   â”‚â”€â”€â”€â”€â–¶â”‚ Postgres â”‚        â”‚
â”‚  â”‚ WebSocketâ”‚     â”‚  Cache   â”‚     â”‚Timescale â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â”‚                                                  â”‚
â”‚       â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ JWT Auth â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 FastAPI ì„œë²„ êµ¬í˜„

#### 5.2.1 í”„ë¡œì íŠ¸ êµ¬ì¡°

```
server/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ pitch.py
â”‚   â”‚   â””â”€â”€ session.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pitch_schema.py
â”‚   â”‚   â””â”€â”€ user_schema.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ pitches.py
â”‚   â”‚   â””â”€â”€ websocket.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pitch_service.py
â”‚   â”‚   â””â”€â”€ analytics_service.py
â”‚   â””â”€â”€ db/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ database.py
â”‚       â””â”€â”€ redis_client.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

#### 5.2.2 í•µì‹¬ ì½”ë“œ

```python
# app/main.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import json

from app.config import settings
from app.db.database import engine, Base
from app.db.redis_client import redis_client
from app.api import auth, pitches, websocket

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ
    Base.metadata.create_all(bind=engine)
    await redis_client.connect()
    yield
    # ì¢…ë£Œ ì‹œ
    await redis_client.disconnect()

app = FastAPI(
    title="AR Strike Zone API",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(auth.router, prefix="/api/auth", tags=["auth"])
app.include_router(pitches.router, prefix="/api/pitches", tags=["pitches"])
app.include_router(websocket.router, prefix="/ws", tags=["websocket"])

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

```python
# app/api/websocket.py
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends
from typing import Dict, Set
import json
import asyncio

from app.schemas.pitch_schema import PitchData
from app.services.pitch_service import PitchService
from app.db.redis_client import redis_client

router = APIRouter()

class ConnectionManager:
    """WebSocket ì—°ê²° ê´€ë¦¬"""
    
    def __init__(self):
        # user_id -> Set[WebSocket]
        self.active_connections: Dict[str, Set[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, user_id: str):
        await websocket.accept()
        if user_id not in self.active_connections:
            self.active_connections[user_id] = set()
        self.active_connections[user_id].add(websocket)
    
    def disconnect(self, websocket: WebSocket, user_id: str):
        if user_id in self.active_connections:
            self.active_connections[user_id].discard(websocket)
    
    async def send_to_user(self, user_id: str, message: dict):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ëª¨ë“  ì—°ê²°ì— ë©”ì‹œì§€ ì „ì†¡"""
        if user_id in self.active_connections:
            for connection in self.active_connections[user_id]:
                try:
                    await connection.send_json(message)
                except:
                    pass
    
    async def broadcast_to_user_web(self, user_id: str, data: dict):
        """ì›¹ í´ë¼ì´ì–¸íŠ¸ì— ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì „ì†¡"""
        # Redis pub/subì„ í†µí•´ ë‹¤ë¥¸ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ì—ë„ ì „íŒŒ
        await redis_client.publish(f"pitch_updates:{user_id}", json.dumps(data))
        await self.send_to_user(user_id, data)

manager = ConnectionManager()

@router.websocket("/pitch/{user_id}")
async def pitch_websocket(websocket: WebSocket, user_id: str):
    """
    ëª¨ë°”ì¼ ì•±ì—ì„œ íˆ¬êµ¬ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ëŠ” WebSocket ì—”ë“œí¬ì¸íŠ¸
    """
    await manager.connect(websocket, user_id)
    pitch_service = PitchService()
    
    try:
        while True:
            # ëª¨ë°”ì¼ì—ì„œ ë°ì´í„° ìˆ˜ì‹ 
            data = await websocket.receive_json()
            
            # ë°ì´í„° ê²€ì¦ ë° ì €ì¥
            pitch_data = PitchData(**data)
            saved_pitch = await pitch_service.save_pitch(user_id, pitch_data)
            
            # ì‹¤ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
            stats = await pitch_service.get_session_stats(user_id)
            
            # ì›¹ í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await manager.broadcast_to_user_web(user_id, {
                "type": "new_pitch",
                "pitch": saved_pitch.dict(),
                "stats": stats
            })
            
            # ì‘ë‹µ
            await websocket.send_json({
                "status": "saved",
                "pitch_id": saved_pitch.id
            })
            
    except WebSocketDisconnect:
        manager.disconnect(websocket, user_id)

@router.websocket("/dashboard/{user_id}")
async def dashboard_websocket(websocket: WebSocket, user_id: str):
    """
    ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ëŠ” WebSocket ì—”ë“œí¬ì¸íŠ¸
    """
    await manager.connect(websocket, f"web_{user_id}")
    
    # Redis pub/sub êµ¬ë…
    pubsub = redis_client.pubsub()
    await pubsub.subscribe(f"pitch_updates:{user_id}")
    
    try:
        async for message in pubsub.listen():
            if message["type"] == "message":
                data = json.loads(message["data"])
                await websocket.send_json(data)
    except WebSocketDisconnect:
        manager.disconnect(websocket, f"web_{user_id}")
        await pubsub.unsubscribe(f"pitch_updates:{user_id}")
```

```python
# app/schemas/pitch_schema.py
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class Point3D(BaseModel):
    x: float
    y: float
    z: float
    timestamp: int  # milliseconds

class PitchData(BaseModel):
    timestamp: int
    trajectory: List[Point3D]
    speed_kmh: float
    judgment: str  # "STRIKE" or "BALL"
    crossing_point: Optional[Point3D] = None
    pitch_type: Optional[str] = None
    
    class Config:
        json_schema_extra = {
            "example": {
                "timestamp": 1702800000000,
                "trajectory": [
                    {"x": 0.0, "y": 18.44, "z": 1.5, "timestamp": 0},
                    {"x": 0.05, "y": 10.0, "z": 1.2, "timestamp": 200},
                    {"x": 0.1, "y": 0.43, "z": 0.8, "timestamp": 450}
                ],
                "speed_kmh": 142.5,
                "judgment": "STRIKE",
                "crossing_point": {"x": 0.1, "y": 0.43, "z": 0.8, "timestamp": 450}
            }
        }

class PitchResponse(PitchData):
    id: int
    user_id: str
    created_at: datetime

class SessionStats(BaseModel):
    total_pitches: int
    strikes: int
    balls: int
    avg_speed: float
    max_speed: float
    strike_rate: float
```

```python
# app/models/pitch.py
from sqlalchemy import Column, Integer, String, Float, DateTime, JSON, ForeignKey
from sqlalchemy.sql import func
from app.db.database import Base

class Pitch(Base):
    __tablename__ = "pitches"
    
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(String, index=True)
    session_id = Column(String, index=True)
    
    timestamp = Column(DateTime, default=func.now())
    trajectory = Column(JSON)  # List of Point3D
    speed_kmh = Column(Float)
    judgment = Column(String)  # STRIKE/BALL
    crossing_point = Column(JSON)  # Point3D
    pitch_type = Column(String, nullable=True)
    
    # ë¶„ì„ ë°ì´í„°
    release_point = Column(JSON, nullable=True)
    break_amount = Column(Float, nullable=True)  # ë³€í™”ëŸ‰
    spin_rate = Column(Float, nullable=True)     # íšŒì „ìˆ˜ (ì¶”í›„ í™•ì¥)
    
    created_at = Column(DateTime, default=func.now())
```

#### 5.2.3 Docker ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/strikezone
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=your-secret-key
    depends_on:
      - db
      - redis
    restart: unless-stopped

  db:
    image: timescale/timescaledb:latest-pg15
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=strikezone
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - api

volumes:
  postgres_data:
  redis_data:
```

### 5.3 ì›¹ ëŒ€ì‹œë³´ë“œ (React)

#### 5.3.1 í”„ë¡œì íŠ¸ êµ¬ì¡°

```
web/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Dashboard/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PitchList.tsx
â”‚   â”‚   â”‚   â””â”€â”€ StatsCard.tsx
â”‚   â”‚   â”œâ”€â”€ Visualization/
â”‚   â”‚   â”‚   â”œâ”€â”€ Trajectory3D.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StrikeZoneHeatmap.tsx
â”‚   â”‚   â”‚   â””â”€â”€ SpeedChart.tsx
â”‚   â”‚   â””â”€â”€ common/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useWebSocket.ts
â”‚   â”‚   â””â”€â”€ usePitchData.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ api.ts
â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â””â”€â”€ pitchStore.ts
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ pitch.ts
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx
â”œâ”€â”€ package.json
â””â”€â”€ vite.config.ts
```

#### 5.3.2 3D ê¶¤ì  ì‹œê°í™” (Three.js)

```typescript
// src/components/Visualization/Trajectory3D.tsx
import React, { useRef, useEffect } from 'react';
import * as THREE from 'three';
import { OrbitControls } from 'three/examples/jsm/controls/OrbitControls';
import { Point3D, PitchData } from '../../types/pitch';

interface Props {
  pitches: PitchData[];
  selectedPitchId?: number;
}

export const Trajectory3D: React.FC<Props> = ({ pitches, selectedPitchId }) => {
  const containerRef = useRef<HTMLDivElement>(null);
  const sceneRef = useRef<THREE.Scene | null>(null);
  const rendererRef = useRef<THREE.WebGLRenderer | null>(null);
  
  useEffect(() => {
    if (!containerRef.current) return;
    
    // Scene ì„¤ì •
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x1a1a2e);
    sceneRef.current = scene;
    
    // Camera ì„¤ì • (í¬ìˆ˜ ì‹œì )
    const camera = new THREE.PerspectiveCamera(
      60,
      containerRef.current.clientWidth / containerRef.current.clientHeight,
      0.1,
      100
    );
    camera.position.set(0, 1.5, -2);  // í¬ìˆ˜ ë’¤ì—ì„œ ë³´ëŠ” ì‹œì 
    camera.lookAt(0, 1, 10);
    
    // Renderer
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(containerRef.current.clientWidth, containerRef.current.clientHeight);
    containerRef.current.appendChild(renderer.domElement);
    rendererRef.current = renderer;
    
    // Controls
    const controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    
    // ì¡°ëª…
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
    scene.add(ambientLight);
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
    directionalLight.position.set(5, 10, 5);
    scene.add(directionalLight);
    
    // ìŠ¤íŠ¸ë¼ì´í¬ ì¡´ ë°•ìŠ¤
    const strikeZoneGeometry = new THREE.BoxGeometry(0.43, 0.56, 0.43);
    const strikeZoneEdges = new THREE.EdgesGeometry(strikeZoneGeometry);
    const strikeZoneLine = new THREE.LineSegments(
      strikeZoneEdges,
      new THREE.LineBasicMaterial({ color: 0x00ff00, linewidth: 2 })
    );
    strikeZoneLine.position.set(0, 0.85, 0);  // í™ˆí”Œë ˆì´íŠ¸ ìœ„ì¹˜
    scene.add(strikeZoneLine);
    
    // í™ˆí”Œë ˆì´íŠ¸
    const plateGeometry = new THREE.PlaneGeometry(0.43, 0.43);
    const plateMaterial = new THREE.MeshBasicMaterial({ 
      color: 0xffffff, 
      side: THREE.DoubleSide,
      transparent: true,
      opacity: 0.5
    });
    const plate = new THREE.Mesh(plateGeometry, plateMaterial);
    plate.rotation.x = -Math.PI / 2;
    plate.position.y = 0.01;
    scene.add(plate);
    
    // ë§ˆìš´ë“œ
    const moundGeometry = new THREE.CircleGeometry(0.5, 32);
    const moundMaterial = new THREE.MeshBasicMaterial({ 
      color: 0x8b4513,
      side: THREE.DoubleSide
    });
    const mound = new THREE.Mesh(moundGeometry, moundMaterial);
    mound.rotation.x = -Math.PI / 2;
    mound.position.set(0, 0.3, 18.44);
    scene.add(mound);
    
    // ê·¸ë¦¬ë“œ
    const gridHelper = new THREE.GridHelper(20, 20, 0x444444, 0x222222);
    scene.add(gridHelper);
    
    // ì• ë‹ˆë©”ì´ì…˜ ë£¨í”„
    const animate = () => {
      requestAnimationFrame(animate);
      controls.update();
      renderer.render(scene, camera);
    };
    animate();
    
    // ë¦¬ì‚¬ì´ì¦ˆ í•¸ë“¤ëŸ¬
    const handleResize = () => {
      if (!containerRef.current) return;
      camera.aspect = containerRef.current.clientWidth / containerRef.current.clientHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(containerRef.current.clientWidth, containerRef.current.clientHeight);
    };
    window.addEventListener('resize', handleResize);
    
    return () => {
      window.removeEventListener('resize', handleResize);
      renderer.dispose();
      containerRef.current?.removeChild(renderer.domElement);
    };
  }, []);
  
  // íˆ¬êµ¬ ê¶¤ì  ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (!sceneRef.current) return;
    
    // ê¸°ì¡´ ê¶¤ì  ì œê±°
    const toRemove: THREE.Object3D[] = [];
    sceneRef.current.traverse((child) => {
      if (child.userData.isPitchTrajectory) {
        toRemove.push(child);
      }
    });
    toRemove.forEach(obj => sceneRef.current?.remove(obj));
    
    // ìƒˆ ê¶¤ì  ì¶”ê°€
    pitches.forEach((pitch, index) => {
      const isSelected = pitch.id === selectedPitchId;
      const color = pitch.judgment === 'STRIKE' ? 0xff4444 : 0x4444ff;
      
      // ê¶¤ì  ë¼ì¸
      const points = pitch.trajectory.map(p => 
        new THREE.Vector3(p.x, p.z, p.y)  // Yì™€ Z êµí™˜ (Three.js ì¢Œí‘œê³„)
      );
      
      const geometry = new THREE.BufferGeometry().setFromPoints(points);
      const material = new THREE.LineBasicMaterial({ 
        color: isSelected ? 0xffff00 : color,
        linewidth: isSelected ? 3 : 1,
        transparent: !isSelected,
        opacity: isSelected ? 1 : 0.5
      });
      
      const line = new THREE.Line(geometry, material);
      line.userData.isPitchTrajectory = true;
      sceneRef.current?.add(line);
      
      // ê³µ ìœ„ì¹˜ (ë§ˆì§€ë§‰ í¬ì¸íŠ¸)
      if (pitch.crossing_point) {
        const sphereGeometry = new THREE.SphereGeometry(0.0365, 16, 16);
        const sphereMaterial = new THREE.MeshBasicMaterial({ color });
        const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
        sphere.position.set(
          pitch.crossing_point.x,
          pitch.crossing_point.z,
          pitch.crossing_point.y
        );
        sphere.userData.isPitchTrajectory = true;
        sceneRef.current?.add(sphere);
      }
    });
  }, [pitches, selectedPitchId]);
  
  return (
    <div 
      ref={containerRef} 
      style={{ width: '100%', height: '500px', borderRadius: '8px', overflow: 'hidden' }}
    />
  );
};
```

#### 5.3.3 ìŠ¤íŠ¸ë¼ì´í¬ ì¡´ íˆíŠ¸ë§µ

```typescript
// src/components/Visualization/StrikeZoneHeatmap.tsx
import React from 'react';
import Plot from 'react-plotly.js';
import { PitchData } from '../../types/pitch';

interface Props {
  pitches: PitchData[];
}

export const StrikeZoneHeatmap: React.FC<Props> = ({ pitches }) => {
  // ì¡´ í†µê³¼ ìœ„ì¹˜ ì¶”ì¶œ
  const crossingPoints = pitches
    .filter(p => p.crossing_point)
    .map(p => ({
      x: p.crossing_point!.x,
      y: p.crossing_point!.z,  // ë†’ì´
      judgment: p.judgment
    }));
  
  // ìŠ¤íŠ¸ë¼ì´í¬/ë³¼ ë¶„ë¦¬
  const strikes = crossingPoints.filter(p => p.judgment === 'STRIKE');
  const balls = crossingPoints.filter(p => p.judgment === 'BALL');
  
  // ìŠ¤íŠ¸ë¼ì´í¬ ì¡´ ê²½ê³„ (ë¯¸í„°)
  const zoneWidth = 0.43 / 2;  // í™ˆí”Œë ˆì´íŠ¸ í­ì˜ ì ˆë°˜
  const zoneBottom = 0.57;     // ë¬´ë¦
  const zoneTop = 1.13;        // ê°€ìŠ´ ì¤‘ê°„
  
  return (
    <Plot
      data={[
        // ìŠ¤íŠ¸ë¼ì´í¬
        {
          x: strikes.map(p => p.x),
          y: strikes.map(p => p.y),
          mode: 'markers',
          type: 'scatter',
          name: 'Strike',
          marker: {
            color: 'red',
            size: 12,
            symbol: 'circle'
          }
        },
        // ë³¼
        {
          x: balls.map(p => p.x),
          y: balls.map(p => p.y),
          mode: 'markers',
          type: 'scatter',
          name: 'Ball',
          marker: {
            color: 'blue',
            size: 12,
            symbol: 'circle'
          }
        }
      ]}
      layout={{
        title: 'íˆ¬êµ¬ ìœ„ì¹˜ ë¶„í¬',
        width: 400,
        height: 500,
        xaxis: {
          title: 'ì¢Œìš° (m)',
          range: [-0.5, 0.5],
          zeroline: true
        },
        yaxis: {
          title: 'ë†’ì´ (m)',
          range: [0.3, 1.5],
          zeroline: false
        },
        shapes: [
          // ìŠ¤íŠ¸ë¼ì´í¬ ì¡´ ë°•ìŠ¤
          {
            type: 'rect',
            x0: -zoneWidth,
            x1: zoneWidth,
            y0: zoneBottom,
            y1: zoneTop,
            line: { color: 'green', width: 3 },
            fillcolor: 'rgba(0, 255, 0, 0.1)'
          }
        ],
        paper_bgcolor: '#1a1a2e',
        plot_bgcolor: '#1a1a2e',
        font: { color: 'white' }
      }}
    />
  );
};
```

#### 5.3.4 WebSocket Hook

```typescript
// src/hooks/useWebSocket.ts
import { useEffect, useRef, useCallback, useState } from 'react';
import { PitchData, SessionStats } from '../types/pitch';

interface WebSocketMessage {
  type: 'new_pitch' | 'stats_update' | 'session_end';
  pitch?: PitchData;
  stats?: SessionStats;
}

export const useWebSocket = (userId: string) => {
  const wsRef = useRef<WebSocket | null>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [lastPitch, setLastPitch] = useState<PitchData | null>(null);
  const [stats, setStats] = useState<SessionStats | null>(null);
  
  const connect = useCallback(() => {
    const ws = new WebSocket(`ws://localhost:8000/ws/dashboard/${userId}`);
    
    ws.onopen = () => {
      console.log('WebSocket connected');
      setIsConnected(true);
    };
    
    ws.onmessage = (event) => {
      const data: WebSocketMessage = JSON.parse(event.data);
      
      switch (data.type) {
        case 'new_pitch':
          if (data.pitch) setLastPitch(data.pitch);
          if (data.stats) setStats(data.stats);
          break;
        case 'stats_update':
          if (data.stats) setStats(data.stats);
          break;
      }
    };
    
    ws.onclose = () => {
      console.log('WebSocket disconnected');
      setIsConnected(false);
      // ìë™ ì¬ì—°ê²°
      setTimeout(connect, 3000);
    };
    
    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };
    
    wsRef.current = ws;
  }, [userId]);
  
  useEffect(() => {
    connect();
    return () => {
      wsRef.current?.close();
    };
  }, [connect]);
  
  return { isConnected, lastPitch, stats };
};
```

---

## 6. Phase 4: ë¬¼ë¦¬ ê¸°ë°˜ íë£¨í”„ ì¶”ì  (2-3ì£¼)

### 6.1 ì¹¼ë§Œ í•„í„° + ë¬¼ë¦¬ ëª¨ë¸

#### 6.1.1 ìƒíƒœ ê³µê°„ ëª¨ë¸

```
ìƒíƒœ ë²¡í„° X = [x, y, z, vx, vy, vz]^T

ìƒíƒœ ì „ì´ ëª¨ë¸ (ë“±ê°€ì†ë„ + ì¤‘ë ¥):
  x(t+1) = x(t) + vx(t)*dt
  y(t+1) = y(t) + vy(t)*dt
  z(t+1) = z(t) + vz(t)*dt - 0.5*g*dtÂ²
  vx(t+1) = vx(t)
  vy(t+1) = vy(t)
  vz(t+1) = vz(t) - g*dt

ì—¬ê¸°ì„œ g = 9.81 m/sÂ², dt = 1/60 s (60fps)
```

#### 6.1.2 êµ¬í˜„ ì½”ë“œ

```kotlin
// PhysicsKalmanTracker.kt
class PhysicsKalmanTracker(
    private val processNoise: Float = 0.1f,
    private val measurementNoise: Float = 0.5f,
    private val gravity: Float = 9.81f
) {
    // ìƒíƒœ ë²¡í„°: [x, y, z, vx, vy, vz]
    private var state = FloatArray(6) { 0f }
    private var covariance = Array(6) { FloatArray(6) { 0f } }
    
    // ìƒíƒœ ì „ì´ í–‰ë ¬ (dtì— ë”°ë¼ ë™ì  ìƒì„±)
    private fun getTransitionMatrix(dt: Float): Array<FloatArray> {
        return arrayOf(
            floatArrayOf(1f, 0f, 0f, dt, 0f, 0f),
            floatArrayOf(0f, 1f, 0f, 0f, dt, 0f),
            floatArrayOf(0f, 0f, 1f, 0f, 0f, dt),
            floatArrayOf(0f, 0f, 0f, 1f, 0f, 0f),
            floatArrayOf(0f, 0f, 0f, 0f, 1f, 0f),
            floatArrayOf(0f, 0f, 0f, 0f, 0f, 1f)
        )
    }
    
    // ì¤‘ë ¥ì— ì˜í•œ ì œì–´ ì…ë ¥
    private fun getControlInput(dt: Float): FloatArray {
        return floatArrayOf(
            0f,
            0f,
            -0.5f * gravity * dt * dt,  // ìœ„ì¹˜ ë³´ì •
            0f,
            0f,
            -gravity * dt               // ì†ë„ ë³´ì •
        )
    }
    
    fun predict(dt: Float): FloatArray {
        val F = getTransitionMatrix(dt)
        val u = getControlInput(dt)
        
        // ìƒíƒœ ì˜ˆì¸¡: x = F*x + u
        val newState = FloatArray(6)
        for (i in 0..5) {
            newState[i] = u[i]
            for (j in 0..5) {
                newState[i] += F[i][j] * state[j]
            }
        }
        
        // ê³µë¶„ì‚° ì˜ˆì¸¡: P = F*P*F^T + Q
        val newCov = Array(6) { FloatArray(6) { 0f } }
        // ... í–‰ë ¬ ì—°ì‚° ...
        
        state = newState
        covariance = newCov
        
        return state.sliceArray(0..2)  // ìœ„ì¹˜ë§Œ ë°˜í™˜
    }
    
    fun update(measurement: FloatArray): FloatArray {
        // ì¸¡ì • í–‰ë ¬ H (ìœ„ì¹˜ë§Œ ê´€ì¸¡)
        val H = arrayOf(
            floatArrayOf(1f, 0f, 0f, 0f, 0f, 0f),
            floatArrayOf(0f, 1f, 0f, 0f, 0f, 0f),
            floatArrayOf(0f, 0f, 1f, 0f, 0f, 0f)
        )
        
        // ì¹¼ë§Œ ì´ë“ ê³„ì‚°
        // K = P*H^T * (H*P*H^T + R)^(-1)
        
        // ìƒíƒœ ì—…ë°ì´íŠ¸
        // x = x + K*(z - H*x)
        
        // ê³µë¶„ì‚° ì—…ë°ì´íŠ¸
        // P = (I - K*H)*P
        
        return state.sliceArray(0..2)
    }
    
    fun updateWithGating(
        measurement: FloatArray,
        gatingThreshold: Float = 0.5f  // ë¯¸í„°
    ): FloatArray? {
        // ì˜ˆì¸¡ ìœ„ì¹˜ì™€ ì¸¡ì • ìœ„ì¹˜ì˜ ê±°ë¦¬
        val predicted = state.sliceArray(0..2)
        val distance = sqrt(
            (predicted[0] - measurement[0]).pow(2) +
            (predicted[1] - measurement[1]).pow(2) +
            (predicted[2] - measurement[2]).pow(2)
        )
        
        return if (distance < gatingThreshold) {
            update(measurement)
        } else {
            // ì´ìƒì¹˜ë¡œ íŒë‹¨, ì—…ë°ì´íŠ¸ ì•ˆ í•¨
            Log.w("Tracker", "Gating rejected: distance=$distance")
            null
        }
    }
    
    fun getPredictedTrajectory(numFrames: Int, dt: Float): List<FloatArray> {
        // í˜„ì¬ ìƒíƒœì—ì„œ ë¯¸ë˜ ê¶¤ì  ì˜ˆì¸¡
        val trajectory = mutableListOf<FloatArray>()
        var tempState = state.copyOf()
        
        for (i in 0 until numFrames) {
            val F = getTransitionMatrix(dt)
            val u = getControlInput(dt)
            
            val newState = FloatArray(6)
            for (j in 0..5) {
                newState[j] = u[j]
                for (k in 0..5) {
                    newState[j] += F[j][k] * tempState[k]
                }
            }
            tempState = newState
            trajectory.add(tempState.sliceArray(0..2))
        }
        
        return trajectory
    }
    
    fun initialize(position: FloatArray, velocity: FloatArray? = null) {
        state[0] = position[0]
        state[1] = position[1]
        state[2] = position[2]
        
        if (velocity != null) {
            state[3] = velocity[0]
            state[4] = velocity[1]
            state[5] = velocity[2]
        } else {
            // ì´ˆê¸° ì†ë„ ì¶”ì • (ì¼ë°˜ì ì¸ íˆ¬êµ¬ ì†ë„)
            state[3] = 0f
            state[4] = -40f  // ì•½ 144 km/h
            state[5] = 0f
        }
        
        // ì´ˆê¸° ê³µë¶„ì‚°
        for (i in 0..5) {
            covariance[i][i] = if (i < 3) 0.1f else 5f
        }
    }
    
    fun getSpeed(): Float {
        return sqrt(state[3]*state[3] + state[4]*state[4] + state[5]*state[5])
    }
    
    fun getSpeedKmh(): Float = getSpeed() * 3.6f
}
```

### 6.2 íë£¨í”„ ê²€ì¶œ-ì¶”ì  í†µí•©

```kotlin
// PitchTracker.kt
class PitchTracker(
    private val detector: TFLiteWrapper,
    private val kalman: PhysicsKalmanTracker,
    private val coordinator: CoordinateTransformer
) {
    enum class TrackingState {
        IDLE,           // ëŒ€ê¸° ì¤‘
        TRACKING,       // ì¶”ì  ì¤‘
        LOST,           // ì¶”ì  ì‹¤íŒ¨
        COMPLETED       // íˆ¬êµ¬ ì™„ë£Œ
    }
    
    private var state = TrackingState.IDLE
    private var trajectory = mutableListOf<Point3D>()
    private var missedFrames = 0
    private val maxMissedFrames = 5  // 5í”„ë ˆì„ ì´ìƒ ë¯¸ê²€ì¶œ ì‹œ ì¢…ë£Œ
    
    // ì˜ì‚¬ ê²€ì¶œ (pseudo-detection) ì‚¬ìš© ì—¬ë¶€
    private var usePseudoDetection = true
    
    fun processFrame(
        frame: Bitmap,
        rvec: FloatArray,
        tvec: FloatArray,
        timestampMs: Long
    ): TrackingResult {
        // 1. ë”¥ëŸ¬ë‹ ê²€ì¶œ
        val detections = detector.detect(frame)
        
        when (state) {
            TrackingState.IDLE -> {
                // ì²« ê²€ì¶œ ëŒ€ê¸°
                if (detections.isNotEmpty()) {
                    val det = detections[0]
                    val pos3D = estimate3DPosition(det, rvec, tvec)
                    
                    // ë§ˆìš´ë“œ ê·¼ì²˜ì—ì„œ ì‹œì‘í–ˆëŠ”ì§€ í™•ì¸
                    if (pos3D[1] > 15f) {  // y > 15m (ë§ˆìš´ë“œ ê·¼ì²˜)
                        kalman.initialize(pos3D)
                        trajectory.add(Point3D(pos3D[0], pos3D[1], pos3D[2], timestampMs))
                        state = TrackingState.TRACKING
                        missedFrames = 0
                    }
                }
            }
            
            TrackingState.TRACKING -> {
                // ì˜ˆì¸¡
                val dt = 1f / 60f
                val predicted = kalman.predict(dt)
                
                if (detections.isNotEmpty()) {
                    // ê²€ì¶œ ì„±ê³µ
                    val det = detections[0]
                    val measured = estimate3DPosition(det, rvec, tvec)
                    
                    // ê²Œì´íŒ… ì ìš© ì—…ë°ì´íŠ¸
                    val updated = kalman.updateWithGating(measured)
                    
                    if (updated != null) {
                        trajectory.add(Point3D(updated[0], updated[1], updated[2], timestampMs))
                        missedFrames = 0
                    } else {
                        // ê²Œì´íŒ… ì‹¤íŒ¨ â†’ ì˜ì‚¬ ê²€ì¶œ ì‚¬ìš©
                        handleMissedDetection(predicted, timestampMs)
                    }
                } else {
                    // ê²€ì¶œ ì‹¤íŒ¨
                    handleMissedDetection(predicted, timestampMs)
                }
                
                // í™ˆí”Œë ˆì´íŠ¸ í†µê³¼ í™•ì¸
                val currentPos = trajectory.lastOrNull()
                if (currentPos != null && currentPos.y < 0.5f) {
                    state = TrackingState.COMPLETED
                }
                
                // ë„ˆë¬´ ë§ì´ ë†“ì³¤ìœ¼ë©´ ì¢…ë£Œ
                if (missedFrames > maxMissedFrames) {
                    state = TrackingState.LOST
                }
            }
            
            else -> { /* LOST, COMPLETED: ì²˜ë¦¬ ì—†ìŒ */ }
        }
        
        return TrackingResult(
            state = state,
            trajectory = trajectory.toList(),
            currentSpeed = kalman.getSpeedKmh(),
            predicted = if (state == TrackingState.TRACKING) 
                kalman.getPredictedTrajectory(10, 1f/60f) 
                else emptyList()
        )
    }
    
    private fun handleMissedDetection(predicted: FloatArray, timestampMs: Long) {
        missedFrames++
        
        if (usePseudoDetection && missedFrames <= 3) {
            // ì˜ì‚¬ ê²€ì¶œ: ì˜ˆì¸¡ ìœ„ì¹˜ë¥¼ ê¶¤ì ì— ì¶”ê°€
            trajectory.add(Point3D(predicted[0], predicted[1], predicted[2], timestampMs))
            Log.d("Tracker", "Using pseudo-detection at frame $missedFrames")
        }
    }
    
    private fun estimate3DPosition(
        detection: Detection,
        rvec: FloatArray,
        tvec: FloatArray
    ): FloatArray {
        // ê¹Šì´ ì¶”ì •
        val pos3D = coordinator.estimateDepth(detection)
        // ë§ˆì»¤ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        return coordinator.transformToMarkerCoord(pos3D, rvec, tvec)
    }
    
    fun reset() {
        state = TrackingState.IDLE
        trajectory.clear()
        missedFrames = 0
    }
    
    fun getJudgment(strikeZone: StrikeZone): PitchJudgment? {
        if (state != TrackingState.COMPLETED) return null
        
        // ì¡´ í†µê³¼ ì§€ì  ì°¾ê¸°
        val crossingPoint = findCrossingPoint(trajectory, strikeZone.frontPlaneY)
        
        return if (crossingPoint != null && strikeZone.isInZone(crossingPoint)) {
            PitchJudgment.STRIKE
        } else {
            PitchJudgment.BALL
        }
    }
    
    private fun findCrossingPoint(trajectory: List<Point3D>, planeY: Float): Point3D? {
        for (i in 1 until trajectory.size) {
            val prev = trajectory[i - 1]
            val curr = trajectory[i]
            
            // Yê°€ planeYë¥¼ í†µê³¼í–ˆëŠ”ì§€ í™•ì¸
            if (prev.y > planeY && curr.y <= planeY) {
                // ì„ í˜• ë³´ê°„
                val t = (planeY - prev.y) / (curr.y - prev.y)
                return Point3D(
                    x = prev.x + t * (curr.x - prev.x),
                    y = planeY,
                    z = prev.z + t * (curr.z - prev.z),
                    timestamp = (prev.timestamp + t * (curr.timestamp - prev.timestamp)).toLong()
                )
            }
        }
        return null
    }
}

data class TrackingResult(
    val state: PitchTracker.TrackingState,
    val trajectory: List<Point3D>,
    val currentSpeed: Float,
    val predicted: List<FloatArray>
)
```

---

## 7. Phase 5: ê³ ê¸‰ ë°ì´í„° ì¦ê°• (2ì£¼)

### 7.1 ëª¨ì…˜ ë¸”ëŸ¬ í•©ì„±

```python
# augmentation/motion_blur.py
import cv2
import numpy as np
from typing import Tuple

def apply_motion_blur(
    image: np.ndarray,
    ball_center: Tuple[int, int],
    ball_radius: int,
    blur_length: int = 15,
    blur_angle: float = 0.0
) -> np.ndarray:
    """
    ê³µ ì˜ì—­ì—ë§Œ ëª¨ì…˜ ë¸”ëŸ¬ ì ìš©
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        ball_center: ê³µ ì¤‘ì‹¬ ì¢Œí‘œ (x, y)
        ball_radius: ê³µ ë°˜ì§€ë¦„ (í”½ì…€)
        blur_length: ë¸”ëŸ¬ ê¸¸ì´ (í”½ì…€)
        blur_angle: ë¸”ëŸ¬ ë°©í–¥ (ë¼ë””ì•ˆ)
    """
    h, w = image.shape[:2]
    
    # ëª¨ì…˜ ë¸”ëŸ¬ ì»¤ë„ ìƒì„±
    kernel_size = blur_length
    kernel = np.zeros((kernel_size, kernel_size))
    
    # ë°©í–¥ì— ë”°ë¥¸ ì»¤ë„ ìƒì„±
    center = kernel_size // 2
    cos_a = np.cos(blur_angle)
    sin_a = np.sin(blur_angle)
    
    for i in range(kernel_size):
        offset = i - center
        x = int(center + offset * cos_a)
        y = int(center + offset * sin_a)
        if 0 <= x < kernel_size and 0 <= y < kernel_size:
            kernel[y, x] = 1
    
    kernel = kernel / kernel.sum()
    
    # ê³µ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„±
    mask = np.zeros((h, w), dtype=np.uint8)
    cv2.circle(mask, ball_center, int(ball_radius * 1.5), 255, -1)
    
    # ë¸”ëŸ¬ ì ìš©
    blurred = cv2.filter2D(image, -1, kernel)
    
    # ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ë¸”ëŸ¬ ì ìš©
    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR) / 255.0
    result = image * (1 - mask_3ch) + blurred * mask_3ch
    
    return result.astype(np.uint8)


def generate_motion_blur_sequence(
    background: np.ndarray,
    ball_image: np.ndarray,
    start_pos: Tuple[int, int],
    end_pos: Tuple[int, int],
    num_frames: int = 30,
    ball_radius: int = 15
) -> list:
    """
    ëª¨ì…˜ ë¸”ëŸ¬ê°€ ì ìš©ëœ ê³µ ì´ë™ ì‹œí€€ìŠ¤ ìƒì„±
    """
    frames = []
    positions = []
    
    for i in range(num_frames):
        t = i / (num_frames - 1)
        
        # í¬ë¬¼ì„  ê¶¤ì  (ì¤‘ë ¥ íš¨ê³¼)
        x = int(start_pos[0] + t * (end_pos[0] - start_pos[0]))
        y = int(start_pos[1] + t * (end_pos[1] - start_pos[1]) + 
                0.5 * 9.81 * (t * 0.5) ** 2 * 100)  # ì¤‘ë ¥ íš¨ê³¼
        
        # ë°°ê²½ì— ê³µ í•©ì„±
        frame = background.copy()
        
        # ê³µ ë¶™ì—¬ë„£ê¸°
        ball_h, ball_w = ball_image.shape[:2]
        y1 = max(0, y - ball_h // 2)
        y2 = min(frame.shape[0], y + ball_h // 2)
        x1 = max(0, x - ball_w // 2)
        x2 = min(frame.shape[1], x + ball_w // 2)
        
        # ì•ŒíŒŒ ë¸”ë Œë”©
        if ball_image.shape[2] == 4:
            alpha = ball_image[:, :, 3:4] / 255.0
            frame[y1:y2, x1:x2] = (
                frame[y1:y2, x1:x2] * (1 - alpha[:y2-y1, :x2-x1]) +
                ball_image[:y2-y1, :x2-x1, :3] * alpha[:y2-y1, :x2-x1]
            )
        
        # ëª¨ì…˜ ë¸”ëŸ¬ ì ìš©
        if i > 0:
            prev_pos = positions[-1]
            angle = np.arctan2(y - prev_pos[1], x - prev_pos[0])
            distance = np.sqrt((x - prev_pos[0])**2 + (y - prev_pos[1])**2)
            blur_length = min(int(distance * 0.8), 20)
            
            if blur_length > 3:
                frame = apply_motion_blur(
                    frame, (x, y), ball_radius, blur_length, angle
                )
        
        frames.append(frame)
        positions.append((x, y))
    
    return frames, positions
```

### 7.2 ë°°ê²½ í•©ì„± (Copy-Paste)

```python
# augmentation/copy_paste.py
import cv2
import numpy as np
import albumentations as A
from pathlib import Path

class BallCopyPaste:
    """ê³µì„ ë‹¤ì–‘í•œ ë°°ê²½ì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸°"""
    
    def __init__(self, ball_templates_dir: str, backgrounds_dir: str):
        self.ball_templates = self._load_templates(ball_templates_dir)
        self.backgrounds = self._load_backgrounds(backgrounds_dir)
        
        # ìƒ‰ìƒ/ë°ê¸° ì¦ê°•
        self.color_aug = A.Compose([
            A.RandomBrightnessContrast(p=0.8),
            A.HueSaturationValue(p=0.5),
            A.GaussNoise(var_limit=(10, 50), p=0.3),
        ])
    
    def _load_templates(self, dir_path: str) -> list:
        templates = []
        for p in Path(dir_path).glob("*.png"):
            img = cv2.imread(str(p), cv2.IMREAD_UNCHANGED)
            if img is not None:
                templates.append(img)
        return templates
    
    def _load_backgrounds(self, dir_path: str) -> list:
        backgrounds = []
        for p in Path(dir_path).glob("*.jpg"):
            img = cv2.imread(str(p))
            if img is not None:
                backgrounds.append(img)
        return backgrounds
    
    def generate(
        self,
        num_samples: int = 100,
        output_size: Tuple[int, int] = (1920, 1080)
    ) -> list:
        """í•©ì„± ì´ë¯¸ì§€ ë° ë¼ë²¨ ìƒì„±"""
        
        samples = []
        
        for _ in range(num_samples):
            # ëœë¤ ë°°ê²½ ì„ íƒ
            bg = np.random.choice(self.backgrounds).copy()
            bg = cv2.resize(bg, output_size)
            
            # ëœë¤ ê³µ í…œí”Œë¦¿ ì„ íƒ
            ball = np.random.choice(self.ball_templates).copy()
            
            # ê³µ í¬ê¸° ì¡°ì • (ê±°ë¦¬ì— ë”°ë¥¸ í¬ê¸° ë³€í™” ì‹œë®¬ë ˆì´ì…˜)
            scale = np.random.uniform(0.5, 2.0)
            new_size = (int(ball.shape[1] * scale), int(ball.shape[0] * scale))
            ball = cv2.resize(ball, new_size)
            
            # ëœë¤ ìœ„ì¹˜
            max_x = output_size[0] - ball.shape[1]
            max_y = output_size[1] - ball.shape[0]
            x = np.random.randint(0, max(1, max_x))
            y = np.random.randint(0, max(1, max_y))
            
            # ìƒ‰ìƒ ì¦ê°•
            ball_rgb = ball[:, :, :3]
            ball_rgb = self.color_aug(image=ball_rgb)['image']
            ball[:, :, :3] = ball_rgb
            
            # í•©ì„±
            result = self._paste_ball(bg, ball, x, y)
            
            # ë¼ë²¨ ìƒì„± (YOLO í˜•ì‹)
            cx = (x + ball.shape[1] / 2) / output_size[0]
            cy = (y + ball.shape[0] / 2) / output_size[1]
            w = ball.shape[1] / output_size[0]
            h = ball.shape[0] / output_size[1]
            
            samples.append({
                'image': result,
                'label': f"0 {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}"
            })
        
        return samples
    
    def _paste_ball(
        self,
        background: np.ndarray,
        ball: np.ndarray,
        x: int,
        y: int
    ) -> np.ndarray:
        """ì•ŒíŒŒ ë¸”ë Œë”©ìœ¼ë¡œ ê³µ í•©ì„±"""
        
        result = background.copy()
        bh, bw = ball.shape[:2]
        
        # ê²½ê³„ ì²´í¬
        x1, x2 = max(0, x), min(background.shape[1], x + bw)
        y1, y2 = max(0, y), min(background.shape[0], y + bh)
        
        bx1, bx2 = max(0, -x), bw - max(0, x + bw - background.shape[1])
        by1, by2 = max(0, -y), bh - max(0, y + bh - background.shape[0])
        
        if ball.shape[2] == 4:
            alpha = ball[by1:by2, bx1:bx2, 3:4] / 255.0
            result[y1:y2, x1:x2] = (
                result[y1:y2, x1:x2] * (1 - alpha) +
                ball[by1:by2, bx1:bx2, :3] * alpha
            ).astype(np.uint8)
        else:
            result[y1:y2, x1:x2] = ball[by1:by2, bx1:bx2]
        
        return result
```

### 7.3 í”„ë ˆì„ ì°¨ë¶„ ì±„ë„

```python
# augmentation/frame_difference.py
import cv2
import numpy as np

class FrameDifferenceChannel:
    """
    ì—°ì† í”„ë ˆì„ ì°¨ë¶„ì„ ì¶”ê°€ ì…ë ¥ ì±„ë„ë¡œ ì‚¬ìš©
    - ì›€ì§ì´ëŠ” ê³µì„ ê°•ì¡°
    - ì •ì  ë°°ê²½ ì œê±° íš¨ê³¼
    """
    
    def __init__(self, threshold: int = 30):
        self.prev_frame = None
        self.threshold = threshold
    
    def compute(self, frame: np.ndarray) -> np.ndarray:
        """
        í˜„ì¬ í”„ë ˆì„ê³¼ ì´ì „ í”„ë ˆì„ì˜ ì°¨ë¶„ ê³„ì‚°
        
        Returns:
            4ì±„ë„ ì´ë¯¸ì§€ (RGB + Difference)
        """
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        if self.prev_frame is None:
            self.prev_frame = gray
            diff = np.zeros_like(gray)
        else:
            # ì ˆëŒ€ ì°¨ë¶„
            diff = cv2.absdiff(gray, self.prev_frame)
            
            # ì„ê³„ê°’ ì ìš©
            _, diff = cv2.threshold(diff, self.threshold, 255, cv2.THRESH_BINARY)
            
            # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            diff = cv2.morphologyEx(diff, cv2.MORPH_OPEN, kernel)
            diff = cv2.dilate(diff, kernel, iterations=1)
            
            self.prev_frame = gray
        
        # 4ì±„ë„ë¡œ ê²°í•©
        result = np.dstack([frame, diff])
        return result
    
    def reset(self):
        self.prev_frame = None


def create_4channel_dataset(
    video_path: str,
    output_dir: str,
    labels_dir: str
):
    """ë¹„ë””ì˜¤ì—ì„œ 4ì±„ë„ í•™ìŠµ ë°ì´í„° ìƒì„±"""
    
    cap = cv2.VideoCapture(video_path)
    diff_channel = FrameDifferenceChannel()
    
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # 4ì±„ë„ ì´ë¯¸ì§€ ìƒì„±
        frame_4ch = diff_channel.compute(frame)
        
        # RGB ì´ë¯¸ì§€ ì €ì¥
        rgb_path = f"{output_dir}/frame_{frame_idx:06d}.jpg"
        cv2.imwrite(rgb_path, frame)
        
        # ì°¨ë¶„ ì±„ë„ ì €ì¥ (ë³„ë„ íŒŒì¼)
        diff_path = f"{output_dir}/frame_{frame_idx:06d}_diff.jpg"
        cv2.imwrite(diff_path, frame_4ch[:, :, 3])
        
        frame_idx += 1
    
    cap.release()
```

### 7.4 ì¦ê°• íŒŒì´í”„ë¼ì¸ í†µí•©

```python
# augmentation/pipeline.py
import albumentations as A
from albumentations.pytorch import ToTensorV2

def get_train_transforms(img_size: int = 416):
    """í•™ìŠµìš© ì¦ê°• íŒŒì´í”„ë¼ì¸"""
    
    return A.Compose([
        # ê¸°í•˜í•™ì  ë³€í™˜
        A.HorizontalFlip(p=0.5),
        A.ShiftScaleRotate(
            shift_limit=0.1,
            scale_limit=0.2,
            rotate_limit=0,  # íšŒì „ì€ ì•ˆ í•¨ (ê³µì€ êµ¬í˜•)
            p=0.5
        ),
        
        # ìƒ‰ìƒ ë³€í™˜
        A.OneOf([
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),
            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=30),
        ], p=0.8),
        
        # ë‚ ì”¨/ì¡°ëª… ì‹œë®¬ë ˆì´ì…˜
        A.OneOf([
            A.RandomSunFlare(src_radius=100, p=0.2),
            A.RandomShadow(p=0.3),
            A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.1),
        ], p=0.3),
        
        # ë…¸ì´ì¦ˆ
        A.OneOf([
            A.GaussNoise(var_limit=(10, 50)),
            A.ISONoise(),
            A.MultiplicativeNoise(),
        ], p=0.3),
        
        # ë¸”ëŸ¬ (ëª¨ì…˜ ë¸”ëŸ¬ í¬í•¨)
        A.OneOf([
            A.MotionBlur(blur_limit=7),
            A.GaussianBlur(blur_limit=5),
            A.MedianBlur(blur_limit=5),
        ], p=0.3),
        
        # ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”
        A.Resize(img_size, img_size),
        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),
        ToTensorV2(),
        
    ], bbox_params=A.BboxParams(
        format='yolo',
        label_fields=['class_labels'],
        min_visibility=0.3
    ))


def get_val_transforms(img_size: int = 416):
    """ê²€ì¦ìš© ë³€í™˜ (ì¦ê°• ì—†ìŒ)"""
    
    return A.Compose([
        A.Resize(img_size, img_size),
        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),
        ToTensorV2(),
    ], bbox_params=A.BboxParams(
        format='yolo',
        label_fields=['class_labels']
    ))
```

---

## 8. í•„ìˆ˜ ì°¸ê³  ë…¼ë¬¸ ëª©ë¡

### 8.1 ê³µ ê²€ì¶œ ë° ì¶”ì 

| ë…¼ë¬¸ | í•µì‹¬ ë‚´ìš© | ê´€ë ¨ì„± |
|------|----------|--------|
| **TrackNet (AVSS 2019)** | í…Œë‹ˆìŠ¤/ë°°ë“œë¯¼í„´ ê³µ ì¶”ì ìš© CNN, íˆíŠ¸ë§µ ì¶œë ¥ | â­â­â­â­â­ |
| "TrackNet: A Deep Learning Network for Tracking High-speed and Tiny Objects in Sports Applications" | ì—°ì† í”„ë ˆì„ ì…ë ¥, ê°€ìš°ì‹œì•ˆ íˆíŠ¸ë§µ ì˜ˆì¸¡ | ê³µ ì¶”ì  íŠ¹í™” |
| **MonoTrack (CVPR 2023)** | ë‹¨ì¼ ì¹´ë©”ë¼ 3D ê³µ ì¶”ì  | â­â­â­â­â­ |
| "MonoTrack: Shuttle Trajectory Reconstruction from Monocular Badminton Video" | í•€í™€ ëª¨ë¸ + ë¬¼ë¦¬ ê¸°ë°˜ ê¶¤ì  ì¶”ì • | ê¹Šì´ ì¶”ì • ì°¸ê³  |
| **Ball 3D Localization (WACV 2024)** | ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê³µ 3D ìœ„ì¹˜ ì¶”ì • | â­â­â­â­ |

### 8.2 ì†Œí˜• ê°ì²´ ê²€ì¶œ

| ë…¼ë¬¸ | í•µì‹¬ ë‚´ìš© | ê´€ë ¨ì„± |
|------|----------|--------|
| **SEMA-YOLO (2025)** | ì–•ì€ ì¸µ ê°•í™”, RFA ëª¨ë“ˆ | â­â­â­â­â­ |
| "SEMA-YOLO: Small Object Detection Enhanced with Multi-Scale Attention" | P4 í—¤ë“œ ì¶”ê°€, ë‹¤ì¤‘ìŠ¤ì¼€ì¼ ì ì‘ | ì•„í‚¤í…ì²˜ ì°¸ê³  |
| **MDSF-YOLO (2024)** | ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŒ½ì°½ ìœµí•© | â­â­â­â­ |
| "Small Object Detection with Multi-scale Dilated Sequence Fusion" | íŒ½ì°½ í•©ì„±ê³±ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ í™•ì¥ | í”¼ì²˜ ìœµí•© ì°¸ê³  |
| **TPH-YOLOv5 (2021)** | íŠ¸ëœìŠ¤í¬ë¨¸ + YOLO | â­â­â­ |

### 8.3 ë¬¼ë¦¬ ê¸°ë°˜ ì¶”ì 

| ë…¼ë¬¸ | í•µì‹¬ ë‚´ìš© | ê´€ë ¨ì„± |
|------|----------|--------|
| **PhyOT (NeurIPS 2023)** | ë¬¼ë¦¬ ì—”ì§„ + ì¹¼ë§Œ í•„í„° + ë”¥ëŸ¬ë‹ | â­â­â­â­â­ |
| "Physics-Informed Object Tracking" | ë‰´í„´ ì—­í•™ í†µí•©, ì˜¤íƒ ì œê±° | í•µì‹¬ ì°¸ê³  |
| **KalmanFormer (2025)** | íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ ì¹¼ë§Œ í•„í„° ë³´ì • | â­â­â­â­ |
| "KalmanFormer: SORT with Deep Learning Motion Model" | ë¹„ì„ í˜• ìš´ë™ í•™ìŠµ, ì˜ì‚¬ê²€ì¶œ ìƒì„± | íë£¨í”„ ì°¸ê³  |
| **Singh et al. (2025)** | YOLO + ìš´ë™í•™ ëª¨ë¸ | â­â­â­â­â­ |
| "Hybrid CNN-Kinematics Tracker for Fast Moving Objects" | 70% ì¶”ì  ì˜¤ì°¨ ê°ì†Œ | ì§ì ‘ ê´€ë ¨ |

### 8.4 ë°ì´í„° ì¦ê°•

| ë…¼ë¬¸ | í•µì‹¬ ë‚´ìš© | ê´€ë ¨ì„± |
|------|----------|--------|
| **Hiemann et al. (2021)** | ìŠ¤í¬ì¸  ê³µ ì „ìš© ì¦ê°• | â­â­â­â­â­ |
| "Ball Detection in Beach Volleyball with Domain-specific Augmentation" | í”„ë ˆì„ ì°¨ë¶„ ì±„ë„, ë¬¼ë¦¬ ê¸°ë°˜ í•©ì„± | ì§ì ‘ ì°¸ê³  |
| **Copy-Paste (CVPR 2021)** | ì¸ìŠ¤í„´ìŠ¤ ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ì¦ê°• | â­â­â­â­ |
| **MixUp / Mosaic** | YOLO ê¸°ë³¸ ì¦ê°• | â­â­â­ |

### 8.5 ëª¨ë°”ì¼ ë”¥ëŸ¬ë‹ ìµœì í™”

| ë…¼ë¬¸/ìë£Œ | í•µì‹¬ ë‚´ìš© | ê´€ë ¨ì„± |
|------|----------|--------|
| **YOLOv8 (Ultralytics 2023)** | ìµœì‹  YOLO ì•„í‚¤í…ì²˜ | â­â­â­â­â­ |
| **TensorFlow Lite ê°€ì´ë“œ** | INT8 ì–‘ìí™”, GPU delegate | â­â­â­â­â­ |
| **EfficientDet (CVPR 2020)** | íš¨ìœ¨ì ì¸ í”¼ì²˜ ìœµí•© | â­â­â­â­ |
| **MobileNetV3 (ICCV 2019)** | ëª¨ë°”ì¼ ë°±ë³¸ | â­â­â­ |

### 8.6 ë…¼ë¬¸ ë‹¤ìš´ë¡œë“œ ë§í¬

```markdown
## í•µì‹¬ ë…¼ë¬¸ (í•„ë…)

1. TrackNet
   - arXiv: https://arxiv.org/abs/1907.03698
   - GitHub: https://github.com/ChgygLin/TrackNet

2. PhyOT (Physics-Informed Object Tracking)
   - arXiv: https://arxiv.org/abs/2312.08650

3. Ball Detection with Domain-specific Augmentation
   - PMC: https://pmc.ncbi.nlm.nih.gov/articles/PMC8124271/

4. YOLOv8
   - Docs: https://docs.ultralytics.com/
   - GitHub: https://github.com/ultralytics/ultralytics

5. SEMA-YOLO
   - MDPI: https://www.mdpi.com/2072-4292/17/11/1917

## ë³´ì¡° ìë£Œ

6. TensorFlow Lite ìµœì í™” ê°€ì´ë“œ
   - https://www.tensorflow.org/lite/performance/best_practices

7. Android CameraX ë¬¸ì„œ
   - https://developer.android.com/training/camerax

8. BaseballCV ì˜¤í”ˆì†ŒìŠ¤ ë°ì´í„°ì…‹
   - https://github.com/BaseballCV/BaseballCV
```

---

## 9. ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸

### 9.1 ì „ì²´ ìŠ¤íƒ ìš”ì•½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ê¸°ìˆ  ìŠ¤íƒ Overview                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ“± Mobile (Android)                                         â”‚
â”‚  â”œâ”€â”€ Language: Kotlin                                        â”‚
â”‚  â”œâ”€â”€ Camera: CameraX (Jetpack)                               â”‚
â”‚  â”œâ”€â”€ ML: TensorFlow Lite 2.14 + GPU Delegate                 â”‚
â”‚  â”œâ”€â”€ CV: OpenCV 4.8 (ArUco)                                  â”‚
â”‚  â”œâ”€â”€ Network: OkHttp + WebSocket                             â”‚
â”‚  â””â”€â”€ TTS: Android TextToSpeech (Offline)                     â”‚
â”‚                                                              â”‚
â”‚  ğŸ–¥ï¸ Backend                                                   â”‚
â”‚  â”œâ”€â”€ Framework: FastAPI (Python 3.11)                        â”‚
â”‚  â”œâ”€â”€ WebSocket: Starlette                                    â”‚
â”‚  â”œâ”€â”€ Database: PostgreSQL 15 + TimescaleDB                   â”‚
â”‚  â”œâ”€â”€ Cache: Redis 7                                          â”‚
â”‚  â”œâ”€â”€ Auth: JWT (PyJWT)                                       â”‚
â”‚  â””â”€â”€ Container: Docker + Docker Compose                      â”‚
â”‚                                                              â”‚
â”‚  ğŸŒ Frontend (Web)                                            â”‚
â”‚  â”œâ”€â”€ Framework: React 18 + TypeScript                        â”‚
â”‚  â”œâ”€â”€ 3D: Three.js                                            â”‚
â”‚  â”œâ”€â”€ Charts: Plotly.js                                       â”‚
â”‚  â”œâ”€â”€ State: Zustand                                          â”‚
â”‚  â”œâ”€â”€ Styling: TailwindCSS                                    â”‚
â”‚  â””â”€â”€ Build: Vite                                             â”‚
â”‚                                                              â”‚
â”‚  ğŸ”¬ ML Training                                               â”‚
â”‚  â”œâ”€â”€ Framework: PyTorch + Ultralytics                        â”‚
â”‚  â”œâ”€â”€ Augmentation: Albumentations                            â”‚
â”‚  â”œâ”€â”€ Experiment: Weights & Biases                            â”‚
â”‚  â””â”€â”€ Export: ONNX â†’ TFLite                                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 ë²„ì „ ë° ì˜ì¡´ì„±

```yaml
# ëª¨ë°”ì¼ (build.gradle)
android:
  compileSdk: 34
  minSdk: 26
  targetSdk: 34

dependencies:
  camerax: 1.3.1
  tensorflow-lite: 2.14.0
  tensorflow-lite-gpu: 2.14.0
  opencv: 4.8.0
  okhttp: 4.12.0
  gson: 2.10.1
  coroutines: 1.7.3

# ë°±ì—”ë“œ (requirements.txt)
python: ">=3.11"
fastapi: ">=0.104.0"
uvicorn: ">=0.24.0"
sqlalchemy: ">=2.0.0"
asyncpg: ">=0.29.0"
redis: ">=5.0.0"
pyjwt: ">=2.8.0"
pydantic: ">=2.5.0"

# í”„ë¡ íŠ¸ì—”ë“œ (package.json)
node: ">=18"
react: "^18.2.0"
three: "^0.159.0"
plotly.js: "^2.27.0"
zustand: "^4.4.0"
tailwindcss: "^3.3.0"

# ML í•™ìŠµ (requirements-ml.txt)
torch: ">=2.1.0"
ultralytics: ">=8.0.200"
albumentations: ">=1.3.0"
opencv-python: ">=4.8.0"
wandb: ">=0.16.0"
```

---

## 10. ì‹¤í—˜ ì„¤ê³„ ë° í‰ê°€

### 10.1 ì‹¤í—˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## í•„ìˆ˜ ì‹¤í—˜ (Ablation Study)

### A. ê²€ì¶œ ëª¨ë¸ ë¹„êµ
- [ ] YOLOv8n vs YOLOv8s (ì •í™•ë„/ì†ë„ trade-off)
- [ ] ì…ë ¥ í•´ìƒë„: 416 vs 512 vs 640
- [ ] ì–‘ìí™”: FP32 vs FP16 vs INT8

### B. ì¦ê°• íš¨ê³¼
- [ ] ê¸°ë³¸ ì¦ê°•ë§Œ vs +ëª¨ì…˜ë¸”ëŸ¬ vs +ë°°ê²½í•©ì„± vs +í”„ë ˆì„ì°¨ë¶„
- [ ] ì¦ê°• ê°•ë„ë³„ ë¹„êµ

### C. ë¬¼ë¦¬ ê¸°ë°˜ ì¶”ì 
- [ ] ë‹¨ìˆœ ì¹¼ë§Œ vs ì¤‘ë ¥ í¬í•¨ ì¹¼ë§Œ vs íë£¨í”„
- [ ] ê²Œì´íŒ… ì„ê³„ê°’ë³„ ë¹„êµ
- [ ] ì˜ì‚¬ê²€ì¶œ ì‚¬ìš© ì—¬ë¶€

### D. ì‹œìŠ¤í…œ í†µí•©
- [ ] End-to-end ì§€ì—° ì‹œê°„
- [ ] ë„¤íŠ¸ì›Œí¬ ìƒíƒœë³„ ì„±ëŠ¥ (ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)
```

### 10.2 í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤

```markdown
## í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì´ìƒì  ì¡°ê±´
- ë§‘ì€ ë‚®, ì •ë©´ ì¹´ë©”ë¼, ë‹¨ìƒ‰ ë°°ê²½
- ëª©í‘œ: mAP > 90%, Recall > 95%

### ì‹œë‚˜ë¦¬ì˜¤ 2: ê¹Œë‹¤ë¡œìš´ ì¡°ê±´
- ì—­ê´‘, í°ìƒ‰ ìœ ë‹ˆí¼, ê´€ì¤‘ì„ ë°°ê²½
- ëª©í‘œ: mAP > 75%, Recall > 85%

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹¤ì‚¬ìš© ì¡°ê±´
- ì•¼ì™¸ í›ˆë ¨ì¥, ë‹¤ì–‘í•œ íˆ¬ìˆ˜
- ëª©í‘œ: íŒì • ì •í™•ë„ > 85%, ì§€ì—° < 200ms

### ì‹œë‚˜ë¦¬ì˜¤ 4: ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
- ì—°ì† 100êµ¬ ì²˜ë¦¬
- ëª©í‘œ: í¬ë˜ì‹œ ì—†ìŒ, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì—†ìŒ
```

### 10.3 ê²°ê³¼ ê¸°ë¡ í…œí”Œë¦¿

```markdown
## ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡

### ì‹¤í—˜ ID: EXP-001
- ë‚ ì§œ: 2024-XX-XX
- ëª©ì : YOLOv8n INT8 ì„±ëŠ¥ ê²€ì¦

### ì„¤ì •
- ëª¨ë¸: YOLOv8n
- ì–‘ìí™”: INT8
- ì…ë ¥: 416x416
- ë””ë°”ì´ìŠ¤: Pixel 6

### ê²°ê³¼
| ì§€í‘œ | ê°’ | ëª©í‘œ | ë‹¬ì„± |
|------|-----|------|------|
| mAP@0.5 | 0.XX | 0.85 | âœ…/âŒ |
| Recall | 0.XX | 0.90 | âœ…/âŒ |
| FPS | XX | 25 | âœ…/âŒ |
| Latency | XXms | 35ms | âœ…/âŒ |

### ê´€ì°°
- ...

### ë‹¤ìŒ ë‹¨ê³„
- ...
```

---

## ë§ˆë¬´ë¦¬

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ë‹¨ê³„ë³„ë¡œ êµ¬í˜„í•˜ë©´:

1. **Phase 0-1 (3-4ì£¼)**: ë°ì´í„° + ëª¨ë¸ â†’ ì‘ë™í•˜ëŠ” ê²€ì¶œê¸°
2. **Phase 2 (3-4ì£¼)**: ì•ˆë“œë¡œì´ë“œ ì•± â†’ í˜„ì¥ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
3. **Phase 3 (3-4ì£¼)**: ì„œë²„ + ì›¹ â†’ ì™„ì „í•œ ì‹œìŠ¤í…œ
4. **Phase 4-5 (4ì£¼)**: ë¬¼ë¦¬ ê¸°ë°˜ + ì¦ê°• â†’ ë…¼ë¬¸ê¸‰ ì„±ëŠ¥

**ì´ ì˜ˆìƒ ê¸°ê°„: ì•½ 3-4ê°œì›”**

ì§ˆë¬¸ì´ë‚˜ ë§‰íˆëŠ” ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´! ğŸš€

